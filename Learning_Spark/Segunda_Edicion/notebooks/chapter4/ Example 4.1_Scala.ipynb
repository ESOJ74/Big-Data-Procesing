{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389b911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.11:4047\n",
       "SparkContext available as 'sc' (version = 3.1.2, master = local[*], app id = local-1633073549378)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48e226c",
   "metadata": {},
   "source": [
    "# Example 4.1\n",
    "\n",
    "This notebook shows Example 4.1 from the book showing how to use SQL on a US Flights Dataset dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9203c5a",
   "metadata": {},
   "source": [
    "Define a UDF to convert the date format into a legible format.\n",
    "\n",
    "Note: the date is a string with year missing, so it might be difficult to do any queries using SQL year() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2320849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toDateFormatUDF: (dStr: String)String\n",
       "res0: String = 02/19 09:25\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toDateFormatUDF(dStr:String) : String  = {\n",
    "  return s\"${dStr(0)}${dStr(1)}${'/'}${dStr(2)}${dStr(3)}${' '}${dStr(4)}${dStr(5)}${':'}${dStr(6)}${dStr(7)}\"\n",
    "}\n",
    "\n",
    "// test  it\n",
    "toDateFormatUDF(\"02190925\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77ce00",
   "metadata": {},
   "source": [
    "Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5592fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$2059/57260457@4e06328b,StringType,List(Some(class[value[0]: string])),Some(class[value[0]: string]),Some(toDateFormatUDF),true,true)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"toDateFormatUDF\", toDateFormatUDF(_:String):String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5115e44e",
   "metadata": {},
   "source": [
    "Read our US departure flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f8fbb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [date: string, delay: int ... 3 more fields]\n",
       "res4: org.apache.spark.sql.DataFrame = [date: string, delay: int ... 3 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark\n",
    "  .read\n",
    "  .format(\"csv\")\n",
    "  .schema(\"date STRING, delay INT, distance INT, origin STRING, destination STRING\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"path\", \"departuredelays.csv\")\n",
    "  .load()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba6054",
   "metadata": {},
   "source": [
    "Test our UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bcf3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|data_format|\n",
      "+-----------+\n",
      "|01/01 12:45|\n",
      "|01/02 06:00|\n",
      "|01/02 12:45|\n",
      "|01/02 06:05|\n",
      "|01/03 12:45|\n",
      "|01/03 06:05|\n",
      "|01/04 12:43|\n",
      "|01/04 06:05|\n",
      "|01/05 12:45|\n",
      "|01/05 06:05|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"toDateFormatUDF(date) as data_format\").show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e144350",
   "metadata": {},
   "source": [
    "Create a temporary view to which we can issue SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bd00130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304df82",
   "metadata": {},
   "source": [
    "Convert all date to date_fm so it's more eligible\n",
    "\n",
    "Note: we are using UDF to convert it on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ca65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+--------+-----------+\n",
      "|date    |delay|distance|origin|destination|date    |date_fm    |\n",
      "+--------+-----+--------+------+-----------+--------+-----------+\n",
      "|01011245|6    |602     |ABE   |ATL        |01011245|01/01 12:45|\n",
      "|01020600|-8   |369     |ABE   |DTW        |01020600|01/02 06:00|\n",
      "|01021245|-2   |602     |ABE   |ATL        |01021245|01/02 12:45|\n",
      "|01020605|-4   |602     |ABE   |ATL        |01020605|01/02 06:05|\n",
      "|01031245|-4   |602     |ABE   |ATL        |01031245|01/03 12:45|\n",
      "|01030605|0    |602     |ABE   |ATL        |01030605|01/03 06:05|\n",
      "|01041243|10   |602     |ABE   |ATL        |01041243|01/04 12:43|\n",
      "|01040605|28   |602     |ABE   |ATL        |01040605|01/04 06:05|\n",
      "|01051245|88   |602     |ABE   |ATL        |01051245|01/05 12:45|\n",
      "|01050605|9    |602     |ABE   |ATL        |01050605|01/05 06:05|\n",
      "+--------+-----+--------+------+-----------+--------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT *, date, toDateFormatUDF(date) AS date_fm FROM us_delay_flights_tbl\").show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e8818b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1391578|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM us_delay_flights_tbl\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3baaa2",
   "metadata": {},
   "source": [
    "### Query 1:\n",
    "\n",
    " Find out all flights whose distance between origin and destination is greater than 1000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "913e4eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT distance, origin, destination FROM us_delay_flights_tbl WHERE distance > 1000 ORDER BY distance DESC\").show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e74ea",
   "metadata": {},
   "source": [
    "A DataFrame equivalent query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fc22cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"distance\", \"origin\", \"destination\").where(col(\"distance\") > 1000).orderBy(desc(\"distance\")).show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15430ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"distance\", \"origin\", \"destination\").where($\"distance\" > 1000).orderBy(desc(\"distance\")).show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc43a2",
   "metadata": {},
   "source": [
    "### Query 2:\n",
    "\n",
    " Find out all flights with 2 hour delays between San Francisco and Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926efe2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-----------+\n",
      "|date    |delay|origin|destination|\n",
      "+--------+-----+------+-----------+\n",
      "|02190925|1638 |SFO   |ORD        |\n",
      "|01031755|396  |SFO   |ORD        |\n",
      "|01022330|326  |SFO   |ORD        |\n",
      "|01051205|320  |SFO   |ORD        |\n",
      "|01190925|297  |SFO   |ORD        |\n",
      "|02171115|296  |SFO   |ORD        |\n",
      "|01071040|279  |SFO   |ORD        |\n",
      "|01051550|274  |SFO   |ORD        |\n",
      "|03120730|266  |SFO   |ORD        |\n",
      "|01261104|258  |SFO   |ORD        |\n",
      "+--------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date, delay, origin, destination \n",
    "FROM us_delay_flights_tbl \n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD' \n",
    "ORDER by delay DESC\n",
    "\"\"\").show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b02ab3",
   "metadata": {},
   "source": [
    "### Query 3:\n",
    "\n",
    "A more complicated query in SQL, let's label all US flights originating from airports with _high_, _medium_, _low_, _no delays_, regardless of destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35d0709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+-------------+\n",
      "|delay|origin|destination|Flight_Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "|333  |ABE   |ATL        |Long Delays  |\n",
      "|305  |ABE   |ATL        |Long Delays  |\n",
      "|275  |ABE   |ATL        |Long Delays  |\n",
      "|257  |ABE   |ATL        |Long Delays  |\n",
      "|247  |ABE   |DTW        |Long Delays  |\n",
      "|247  |ABE   |ATL        |Long Delays  |\n",
      "|219  |ABE   |ORD        |Long Delays  |\n",
      "|211  |ABE   |ATL        |Long Delays  |\n",
      "|197  |ABE   |DTW        |Long Delays  |\n",
      "|192  |ABE   |ORD        |Long Delays  |\n",
      "+-----+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT delay, origin, destination,\n",
    "              CASE\n",
    "                  WHEN delay > 360 THEN 'Very Long Delays'\n",
    "                  WHEN delay > 120 AND delay < 360 THEN  'Long Delays '\n",
    "                  WHEN delay > 60 AND delay < 120 THEN  'Short Delays'\n",
    "                  WHEN delay > 0 and delay < 60  THEN   'Tolerable Delays'\n",
    "                  WHEN delay = 0 THEN 'No Delays'\n",
    "                  ELSE 'No Delays'\n",
    "               END AS Flight_Delays\n",
    "               FROM us_delay_flights_tbl\n",
    "               ORDER BY origin, delay DESC\"\"\").show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d50870",
   "metadata": {},
   "source": [
    "Some Side Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e02e7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [date: string, delay: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df1 =  spark.sql(\"SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'SFO'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0279e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceGlobalTempView(\"us_origin_airport_SFO_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bd11def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [date: string, delay: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = spark.sql(\"SELECT date, delay, origin, destination from us_delay_flights_tbl WHERE origin = 'JFK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47dccf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"us_origin_airport_JFK_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "893f7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----------+-----------+---------+-----------+\n",
      "|name                          |database   |description|tableType|isTemporary|\n",
      "+------------------------------+-----------+-----------+---------+-----------+\n",
      "|us_origin_airport_sfo_tmp_view|global_temp|null       |TEMPORARY|true       |\n",
      "|us_delay_flights_tbl          |null       |null       |TEMPORARY|true       |\n",
      "|us_origin_airport_jfk_tmp_view|null       |null       |TEMPORARY|true       |\n",
      "+------------------------------+-----------+-----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.catalog.listTables(dbName=\"global_temp\").show(truncate=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b9c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
