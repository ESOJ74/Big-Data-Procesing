{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea8e5b9",
   "metadata": {},
   "source": [
    "This notebook shows Example 4.1 from the book showing how to use SQL on a US Flights Dataset dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aac3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38629db7",
   "metadata": {},
   "source": [
    "Define a UDF to convert the date format into a legible format.\n",
    "\n",
    "Note: the date is a string with year missing, so it might be difficult to do any queries using SQL year() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad40d8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02/19  09:25'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_date_format_udf(d_str):\n",
    "  l = [char for char in d_str]\n",
    "  return \"\".join(l[0:2]) + \"/\" +  \"\".join(l[2:4]) + \" \" + \" \" +\"\".join(l[4:6]) + \":\" + \"\".join(l[6:])\n",
    "\n",
    "to_date_format_udf(\"02190925\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fada88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Example-3_6\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d976c4c2",
   "metadata": {},
   "source": [
    "Register the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd24226a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.to_date_format_udf(d_str)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.udf.register(\"to_date_format_udf\", to_date_format_udf, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32942da5",
   "metadata": {},
   "source": [
    "Read our US departure flight data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1aee6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[date: string, delay: int, distance: int, origin: string, destination: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (spark.read.format(\"csv\")\n",
    "      .schema(\"date STRING, delay INT, distance INT, origin STRING, destination STRING\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"path\", \"departuredelays.csv\")\n",
    "      .load())\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db851a",
   "metadata": {},
   "source": [
    "Test our UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72d1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|data_format |\n",
      "+------------+\n",
      "|01/01  12:45|\n",
      "|01/02  06:00|\n",
      "|01/02  12:45|\n",
      "|01/02  06:05|\n",
      "|01/03  12:45|\n",
      "|01/03  06:05|\n",
      "|01/04  12:43|\n",
      "|01/04  06:05|\n",
      "|01/05  12:45|\n",
      "|01/05  06:05|\n",
      "+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"to_date_format_udf(date) as data_format\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b2e00",
   "metadata": {},
   "source": [
    "Create a temporary view to which we can issue SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d648c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76fc29",
   "metadata": {},
   "source": [
    "Convert all date to date_fm so it's more eligible\n",
    "\n",
    "Note: we are using UDF to convert it on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ee33d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+--------+------+-----------+--------+------------+\n",
      "|date    |delay|distance|origin|destination|date    |date_fm     |\n",
      "+--------+-----+--------+------+-----------+--------+------------+\n",
      "|01011245|6    |602     |ABE   |ATL        |01011245|01/01  12:45|\n",
      "|01020600|-8   |369     |ABE   |DTW        |01020600|01/02  06:00|\n",
      "|01021245|-2   |602     |ABE   |ATL        |01021245|01/02  12:45|\n",
      "|01020605|-4   |602     |ABE   |ATL        |01020605|01/02  06:05|\n",
      "|01031245|-4   |602     |ABE   |ATL        |01031245|01/03  12:45|\n",
      "|01030605|0    |602     |ABE   |ATL        |01030605|01/03  06:05|\n",
      "|01041243|10   |602     |ABE   |ATL        |01041243|01/04  12:43|\n",
      "|01040605|28   |602     |ABE   |ATL        |01040605|01/04  06:05|\n",
      "|01051245|88   |602     |ABE   |ATL        |01051245|01/05  12:45|\n",
      "|01050605|9    |602     |ABE   |ATL        |01050605|01/05  06:05|\n",
      "+--------+-----+--------+------+-----------+--------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT *, date, to_date_format_udf(date) AS date_fm FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1e0efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 1391578|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT COUNT(*) FROM us_delay_flights_tbl\").show() # Keep case consistent for all SQL??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521559c",
   "metadata": {},
   "source": [
    "Query 1:\n",
    "Find out all flights whose distance between origin and destination is greater than 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac7735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT distance, origin, destination FROM us_delay_flights_tbl WHERE distance > 1000 ORDER BY distance DESC\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed053cfe",
   "metadata": {},
   "source": [
    "A DataFrame equivalent query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee313d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "|4330    |HNL   |JFK        |\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"distance\", \"origin\", \"destination\").where(col(\"distance\") > 1000).orderBy(desc(\"distance\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d338a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"distance\", \"origin\", \"destination\").where(\"distance > 1000\").orderBy(\"distance\", ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d51c06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"distance\", \"origin\", \"destination\").where(\"distance > 1000\").orderBy(desc(\"distance\")).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a4061",
   "metadata": {},
   "source": [
    "Query 2:\n",
    "Find out all flights with 2 hour delays between San Francisco and Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0579dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+-----------+\n",
      "|date    |delay|origin|destination|\n",
      "+--------+-----+------+-----------+\n",
      "|02190925|1638 |SFO   |ORD        |\n",
      "|01031755|396  |SFO   |ORD        |\n",
      "|01022330|326  |SFO   |ORD        |\n",
      "|01051205|320  |SFO   |ORD        |\n",
      "|01190925|297  |SFO   |ORD        |\n",
      "|02171115|296  |SFO   |ORD        |\n",
      "|01071040|279  |SFO   |ORD        |\n",
      "|01051550|274  |SFO   |ORD        |\n",
      "|03120730|266  |SFO   |ORD        |\n",
      "|01261104|258  |SFO   |ORD        |\n",
      "+--------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT date, delay, origin, destination \n",
    "FROM us_delay_flights_tbl \n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD' \n",
    "ORDER by delay DESC\n",
    "\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576463c",
   "metadata": {},
   "source": [
    "Query 3:\n",
    "A more complicated query in SQL, let's label all US flights originating from airports with high, medium, low, no delays, regardless of destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ba20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+-------------+\n",
      "|delay|origin|destination|Flight_Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "|333  |ABE   |ATL        |Long Delays  |\n",
      "|305  |ABE   |ATL        |Long Delays  |\n",
      "|275  |ABE   |ATL        |Long Delays  |\n",
      "|257  |ABE   |ATL        |Long Delays  |\n",
      "|247  |ABE   |ATL        |Long Delays  |\n",
      "|247  |ABE   |DTW        |Long Delays  |\n",
      "|219  |ABE   |ORD        |Long Delays  |\n",
      "|211  |ABE   |ATL        |Long Delays  |\n",
      "|197  |ABE   |DTW        |Long Delays  |\n",
      "|192  |ABE   |ORD        |Long Delays  |\n",
      "+-----+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT delay, origin, destination,\n",
    "              CASE\n",
    "                  WHEN delay > 360 THEN 'Very Long Delays'\n",
    "                  WHEN delay > 120 AND delay < 360 THEN  'Long Delays '\n",
    "                  WHEN delay > 60 AND delay < 120 THEN  'Short Delays'\n",
    "                  WHEN delay > 0 and delay < 60  THEN   'Tolerable Delays'\n",
    "                  WHEN delay = 0 THEN 'No Delays'\n",
    "                  ELSE 'No Delays'\n",
    "               END AS Flight_Delays\n",
    "               FROM us_delay_flights_tbl\n",
    "               ORDER BY origin, delay DESC\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2465e0",
   "metadata": {},
   "source": [
    "Some Side Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d61ba368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =  spark.sql(\"SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'SFO'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6e61ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceGlobalTempView(\"us_origin_airport_SFO_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038c0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT date, delay, origin, destination from us_delay_flights_tbl WHERE origin = 'JFK'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8517d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"us_origin_airport_JFK_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "915f9b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='us_origin_airport_sfo_tmp_view', database='global_temp', description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='us_delay_flights_tbl', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='us_origin_airport_jfk_tmp_view', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables(dbName=\"global_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521205e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
