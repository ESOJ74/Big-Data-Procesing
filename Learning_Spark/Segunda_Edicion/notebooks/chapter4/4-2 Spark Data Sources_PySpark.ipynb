{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002acbac",
   "metadata": {},
   "source": [
    "Spark Data Sources\n",
    "This notebook shows how to use Spark Data Sources Interface API to read file formats:\n",
    "\n",
    "* Parquet\n",
    "* JSON\n",
    "* CSV\n",
    "* Avro\n",
    "* ORC\n",
    "* Image\n",
    "* Binary\n",
    "\n",
    "A full list of DataSource methods is available here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa75f0e",
   "metadata": {},
   "source": [
    "Define paths for the various data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8beb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = \"../../databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet\"\n",
    "json_file = \"../../databricks-datasets/learning-spark-v2/flights/summary-data/json/*\"\n",
    "csv_file = \"../../databricks-datasets/learning-spark-v2/flights/summary-data/csv/*\"\n",
    "orc_file = \"../../databricks-datasets/learning-spark-v2/flights/summary-data/orc/*\"\n",
    "avro_file = \"../../databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\"\n",
    "schema = \"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9314704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Example-3_6\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.1.2\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726b05a",
   "metadata": {},
   "source": [
    "## Parquet Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4956051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "      .format(\"parquet\")\n",
    "      .option(\"path\", parquet_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df60ba3",
   "metadata": {},
   "source": [
    "Another way to read this same data using a variation of this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b34ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f3a10",
   "metadata": {},
   "source": [
    "## Use SQL\n",
    "This will create an unmanaged temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0df8cb3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-fc3ea6dccaa4>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-fc3ea6dccaa4>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "    USING parquet\n",
    "    OPTIONS (\n",
    "      path \"/databricks-datasets/definitive-guide/data/flight-data/parquet/2010-summary.parquet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9fe72",
   "metadata": {},
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5db70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: us_delay_flights_tbl; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [us_delay_flights_tbl], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ca2c8a777029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM us_delay_flights_tbl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: us_delay_flights_tbl; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [us_delay_flights_tbl], [], false\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM us_delay_flights_tbl\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3abf9",
   "metadata": {},
   "source": [
    "## JSON Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb8056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"path\", json_file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe8b34ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "|United States    |Singapore          |1    |\n",
      "|United States    |Grenada            |62   |\n",
      "|Costa Rica       |United States      |588  |\n",
      "|Senegal          |United States      |40   |\n",
      "|Moldova          |United States      |1    |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48bc6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e372331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "|United States    |Singapore          |1    |\n",
      "|United States    |Grenada            |62   |\n",
      "|Costa Rica       |United States      |588  |\n",
      "|Senegal          |United States      |40   |\n",
      "|Moldova          |United States      |1    |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828930b",
   "metadata": {},
   "source": [
    "## CSV Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb4f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "\t .format(\"csv\")\n",
    "\t .option(\"header\", \"true\")\n",
    "\t .schema(schema)\n",
    "\t .option(\"mode\", \"FAILFAST\")  # exit if any errors\n",
    "\t .option(\"nullValue\", \"\")\t  # replace any null data field with “”\n",
    "\t .option(\"path\", csv_file)\n",
    "\t .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9908135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a78af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write.format(\"parquet\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"path\", \"/tmp/data/parquet/df_parquet\")\n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf53985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: fs: orden no encontrada\r\n"
     ]
    }
   ],
   "source": [
    "!fs ls /tmp/data/parquet/df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8bb71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (spark\n",
    "       .read\n",
    "       .option(\"header\", \"true\")\n",
    "       .option(\"mode\", \"FAILFAST\")\t # exit if any errors\n",
    "       .option(\"nullValue\", \"\")\n",
    "       .schema(schema)\n",
    "       .csv(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f166f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97aae7",
   "metadata": {},
   "source": [
    "## ORC Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf94300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"orc\")\n",
    "      .option(\"path\", orc_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8184e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3690ef",
   "metadata": {},
   "source": [
    "## Avro Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ea4ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"avro\")\n",
    "      .option(\"path\", avro_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0e791b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31463a",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4535fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+------+-----+---------+----+-----+\n",
      "|height|width|nChannels|mode|label|\n",
      "+------+-----+---------+----+-----+\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |1    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "+------+-----+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import image\n",
    "\n",
    "image_dir = \"../../databricks-datasets/learning-spark-v2/cctvVideos/train_images/\"\n",
    "images_df = spark.read.format(\"image\").load(image_dir)\n",
    "images_df.printSchema()\n",
    "\n",
    "images_df.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\", \"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac969e",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5691bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../databricks-datasets/learning-spark-v2/cctvVideos/train_images/\"\n",
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "  .load(path))\n",
    "\n",
    "binary_files_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e331e",
   "metadata": {},
   "source": [
    "To ignore any partitioning data discovery in a directory, you can set the recursiveFileLookup to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9321bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "   .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "   .option(\"recursiveFileLookup\", \"true\")\n",
    "   .load(path))\n",
    "binary_files_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18271114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
