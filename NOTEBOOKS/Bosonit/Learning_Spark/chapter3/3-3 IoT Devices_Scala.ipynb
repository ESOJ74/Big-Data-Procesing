{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30f7fdc",
   "metadata": {},
   "source": [
    "# IoT Devices\n",
    "\n",
    "Define a Scala case class that will map to a Scala Dataset: _DeviceIoTData_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class DeviceIoTData (battery_level: Long, c02_level: Long, \n",
    "    cca2: String, cca3: String, cn: String, device_id: Long, \n",
    "    device_name: String, humidity: Long, ip: String, latitude: Double,\n",
    "    lcd: String, longitude: Double, scale:String, temp: Long, timestamp: Long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661d955",
   "metadata": {},
   "source": [
    "Define a Scala case class that will map to a Scala Dataset: _DeviceTempByCountry_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e88d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class DeviceTempByCountry(temp: Long, device_name: String, device_id: Long, cca3: String)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e739a",
   "metadata": {},
   "source": [
    "Read JSON files with device information\n",
    "\n",
    "1. The DataFrameReader will return a DataFrame and convert to Dataset[DeviceIotData]\n",
    "2. DS is a collection of Dataset that map to Scala case class _DeviceIotData_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e70795",
   "metadata": {},
   "outputs": [],
   "source": [
    "val ds = spark.read.json(\"iot_devices.json\").as[DeviceIoTData]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7367f5",
   "metadata": {},
   "source": [
    "Schema maps to each field and type in the Scala case class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765a6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad3b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9a694",
   "metadata": {},
   "source": [
    "Use Dataset API to filter temperature and humidity. Note the use of object.field syntax employed with Dataset JVM, similar to accessing JavaBean fields. This syntax is not only readable but compile type-safe too.\n",
    "\n",
    "For example, if you compared d.temp > \"30\", you will get an compile error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "//val filterTempDS = ds.filter(d => {d.temp > 30 && d.humidity > 70})\n",
    "val filterTempDS = ds.filter($\"temp\" > 30 && $\"humidity\" > 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTempDS.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35569440",
   "metadata": {},
   "source": [
    "Use a more complicated query with lambda functions with the original Dataset DeviceIoTData. Note the awkward column names prefix _1, _2, etc. This is Spark way of handling unknown columns names returned from a Dataset when using queries with lambda expressions. We just renamed them and cast them to our defined case class DeviceTempByCountry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2b36df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------+----+\n",
      "|temp|         device_name|device_id|cca3|\n",
      "+----+--------------------+---------+----+\n",
      "|  34|meter-gauge-1xbYRYcj|        1| USA|\n",
      "|  28|   sensor-pad-4mzWkz|        4| USA|\n",
      "|  27|sensor-pad-6al7RT...|        6| USA|\n",
      "|  27|sensor-pad-8xUD6p...|        8| JPN|\n",
      "|  26|sensor-pad-10Bsyw...|       10| USA|\n",
      "|  31|meter-gauge-17zb8...|       17| USA|\n",
      "|  31|sensor-pad-18XULN9Xv|       18| CHN|\n",
      "|  29|meter-gauge-19eg1...|       19| USA|\n",
      "|  30|  device-mac-21sjz5h|       21| AUT|\n",
      "|  28|sensor-pad-24Pytz...|       24| CAN|\n",
      "+----+--------------------+---------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dsTemp: org.apache.spark.sql.DataFrame = [temp: bigint, device_name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dsTemp = ds\n",
    "  .filter($\"temp\" > 25)\n",
    "  .withColumnRenamed(\"_1\", \"temp\")\n",
    "  .withColumnRenamed(\"_2\", \"device_name\")\n",
    "  .withColumnRenamed(\"_3\", \"device_id\")\n",
    "  .withColumnRenamed(\"_4\", \"cca3\").as[DeviceTempByCountry]\n",
    "  .select($\"temp\", $\"device_name\", $\"device_id\", $\"cca3\")\n",
    "\n",
    "dsTemp.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a983d34b",
   "metadata": {},
   "source": [
    "This query returns a Dataset[Row] since we don't have a corresponding case class to convert to, so a generic Row object is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bb5c2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+---------+--------+----+-------------+\n",
      "|temp|device_name          |device_id|humidity|cca3|cn           |\n",
      "+----+---------------------+---------+--------+----+-------------+\n",
      "|34  |meter-gauge-1xbYRYcj |1        |51      |USA |United States|\n",
      "|28  |sensor-pad-4mzWkz    |4        |32      |USA |United States|\n",
      "|27  |sensor-pad-6al7RTAobR|6        |51      |USA |United States|\n",
      "|27  |sensor-pad-8xUD6pzsQI|8        |35      |JPN |Japan        |\n",
      "|26  |sensor-pad-10BsywSYUF|10       |56      |USA |United States|\n",
      "+----+---------------------+---------+--------+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select($\"temp\", $\"device_name\", $\"device_id\", $\"humidity\", $\"cca3\", $\"cn\").where(\"temp > 25\").show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa292dc",
   "metadata": {},
   "source": [
    "Use the first() method to peek at first DeviceTempByCountry object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c5c658e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device: org.apache.spark.sql.Row = [34,meter-gauge-1xbYRYcj,1,USA]\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val device = dsTemp.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a28c9d",
   "metadata": {},
   "source": [
    "** Q-1) How to detect failing devices with low battery below a threshold?**\n",
    "\n",
    "Note: threshold level less than 8 are potential candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b10c886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----------------------------+\n",
      "|battery_level|c02_level|device_name                 |\n",
      "+-------------+---------+----------------------------+\n",
      "|4            |800      |meter-gauge-113569ucj1L     |\n",
      "|4            |800      |device-mac-111327FkK365     |\n",
      "|6            |800      |sensor-pad-118976n1jeLj     |\n",
      "|7            |800      |sensor-pad-194806J7sArv     |\n",
      "|6            |800      |meter-gauge-19390710h1TvoZMt|\n",
      "+-------------+---------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.select($\"battery_level\", $\"c02_level\", $\"device_name\").where($\"battery_level\" < 8).sort($\"c02_level\").show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3fcdde",
   "metadata": {},
   "source": [
    "** Q-2) How to identify offending countries with high-levels of C02 emissions?**\n",
    "\n",
    "Note: Any C02 levels above 1300 are potential violators of C02 emissions\n",
    "\n",
    "Filter out c02_levels is eater than 1300, sort in descending order on C02_level. Note that this high-level domain specific language API reads like a SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6e81106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+------------------+--------------+--------------+-------------+-------------+------------------+---------+------------------+\n",
      "|cn                            |avg(battery_level)|avg(c02_level)|avg(device_id)|avg(humidity)|avg(latitude)|avg(longitude)    |avg(temp)|avg(timestamp)    |\n",
      "+------------------------------+------------------+--------------+--------------+-------------+-------------+------------------+---------+------------------+\n",
      "|Solomon Islands               |3.0               |1588.0        |187433.0      |40.0         |-9.43        |159.95            |21.0     |1.458444060894E12 |\n",
      "|Federated States of Micronesia|3.0               |1573.0        |78806.0       |55.0         |6.92         |158.25            |13.0     |1.45844405755E12  |\n",
      "|Rwanda                        |2.5               |1560.5        |102085.0      |44.0         |-2.0         |30.0              |21.5     |1.458444058393E12 |\n",
      "|British Indian Ocean Territory|7.0               |1560.0        |83930.0       |54.0         |-6.0         |71.5              |27.0     |1.458444057649E12 |\n",
      "|Aruba                         |4.0               |1559.0        |99899.0       |84.0         |12.51        |-70.0             |19.5     |1.458444057927E12 |\n",
      "|Isle of Man                   |5.0               |1548.0        |137958.5      |46.5         |54.23        |-4.57             |24.5     |1.4584440593755E12|\n",
      "|Gambia                        |3.0               |1544.5        |34748.0       |66.0         |13.47        |-16.57            |16.0     |1.458444056277E12 |\n",
      "|Lesotho                       |2.5               |1537.5        |74949.0       |72.0         |-29.41       |27.990000000000002|21.0     |1.458444057568E12 |\n",
      "|Cuba                          |5.2               |1534.8        |66819.2       |42.0         |21.444       |-79.336           |26.6     |1.4584440572212E12|\n",
      "|Gabon                         |8.0               |1523.0        |106953.0      |30.0         |0.38         |9.45              |28.0     |1.45844405847E12  |\n",
      "+------------------------------+------------------+--------------+--------------+-------------+-------------+------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newDS: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [cn: string, avg(battery_level): double ... 7 more fields]\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newDS = ds\n",
    "  .filter($\"c02_level\" > 1300)\n",
    "  .groupBy($\"cn\")\n",
    "  .avg()\n",
    "  .sort($\"avg(c02_level)\".desc)\n",
    "\n",
    "newDS.show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29da1b8",
   "metadata": {},
   "source": [
    "** Q-3) Can we sort and group country with average temperature, C02, and humidity?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "933e7320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+-------------+\n",
      "|cn                    |avg(temp)|avg(humidity)|\n",
      "+----------------------+---------+-------------+\n",
      "|Monaco                |34.0     |91.0         |\n",
      "|Anguilla              |34.0     |83.0         |\n",
      "|British Virgin Islands|34.0     |81.0         |\n",
      "|Turkmenistan          |34.0     |80.0         |\n",
      "|Suriname              |34.0     |79.0         |\n",
      "|Gibraltar             |34.0     |78.0         |\n",
      "|Liechtenstein         |34.0     |76.0         |\n",
      "|Vanuatu               |33.5     |84.0         |\n",
      "|Cameroon              |33.0     |91.0         |\n",
      "|Fiji                  |33.0     |78.0         |\n",
      "+----------------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.filter($\"temp\" > 25 and $\"humidity\" > 75)\n",
    "  .select(\"temp\", \"humidity\", \"cn\")\n",
    "  .groupBy($\"cn\")\n",
    "  .avg()\n",
    "  .sort($\"avg(temp)\".desc, $\"avg(humidity)\".desc).as(\"avg_humidity\").show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101bc07",
   "metadata": {},
   "source": [
    "Q-4) Can we compute min, max values for temperature, C02, and humidity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35672581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------+-------------+--------------+--------------+------------------+------------------+\n",
      "|min(temp)|max(temp)|min(humidity)|max(humidity)|min(c02_level)|max(c02_level)|min(battery_level)|max(battery_level)|\n",
      "+---------+---------+-------------+-------------+--------------+--------------+------------------+------------------+\n",
      "|       10|       34|           25|           99|           800|          1599|                 0|                 9|\n",
      "+---------+---------+-------------+-------------+--------------+--------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._ \n",
    "\n",
    "ds.select(min(\"temp\"), max(\"temp\"), min(\"humidity\"), max(\"humidity\"), min(\"c02_level\"), max(\"c02_level\"), min(\"battery_level\"), max(\"battery_level\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c92190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
