{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Creación de Nuevas Variables - Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "#sc = SparkContext()\n",
    "#from pyspark.sql import SQLContext\n",
    "#sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd5 = sqlContext.read.format(\n",
    "    \"com.databricks.spark.csv\"\n",
    ").option(\"header\", \"true\").load(\"file:/home/cloudera/Documents/Ficheros de trabajo/bd5.csv\", inferSchema=True)\n",
    "sqlContext.registerDataFrameAsTable(bd5, \"bd5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd5 = bd5.withColumn('Horario1',(bd5.Horario==1) \n",
    ").withColumn('Horario2',(bd5.Horario==2) \n",
    ").withColumn('Horario3',(bd5.Horario==3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Discretizadas Binarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Year=2016, Month=12, DayofMonth=9, DayOfWeek=5, CRSDepTime=815, UniqueCarrier='WN', TailNum='N8322X', ArrDelay=-16.0, DepDelay=0.0, Origin='LAS', Dest='ATL', Distance=1747.0, Cancelled=0.0, Diverted=0.0, CarrierDelay=0.0, WeatherDelay=0.0, NASDelay=0.0, SecurityDelay=0.0, LateAircraftDelay=0.0, LogD=3.2422929049829303, Retraso=0, RetrasoNeto=-16.0, Horario=2, Horario1=False, Horario2=True, Horario3=False, SalidaBin=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=15.0, inputCol='DepDelay', outputCol='SalidaBin')\n",
    "binarizer.transform(bd5).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|DepDelay|SalidaBin|\n",
      "+--------+---------+\n",
      "|     0.0|      0.0|\n",
      "|     0.0|      0.0|\n",
      "|    -2.0|      0.0|\n",
      "|   130.0|      1.0|\n",
      "|    -8.0|      0.0|\n",
      "|     2.0|      0.0|\n",
      "|    11.0|      0.0|\n",
      "|    -2.0|      0.0|\n",
      "|    -3.0|      0.0|\n",
      "|    -3.0|      0.0|\n",
      "|     2.0|      0.0|\n",
      "|    -4.0|      0.0|\n",
      "|     1.0|      0.0|\n",
      "|     6.0|      0.0|\n",
      "|    -4.0|      0.0|\n",
      "|    18.0|      1.0|\n",
      "|     0.0|      0.0|\n",
      "|     0.0|      0.0|\n",
      "|     7.0|      0.0|\n",
      "|    -3.0|      0.0|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binarizer.transform(bd5).select('DepDelay','SalidaBin').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Discretizadas en Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|DepDelay|SalidaCat|\n",
      "+--------+---------+\n",
      "|     0.0|      1.0|\n",
      "|     0.0|      1.0|\n",
      "|    -2.0|      0.0|\n",
      "|   130.0|      2.0|\n",
      "|    -8.0|      0.0|\n",
      "|     2.0|      1.0|\n",
      "|    11.0|      1.0|\n",
      "|    -2.0|      0.0|\n",
      "|    -3.0|      0.0|\n",
      "|    -3.0|      0.0|\n",
      "|     2.0|      1.0|\n",
      "|    -4.0|      0.0|\n",
      "|     1.0|      1.0|\n",
      "|     6.0|      1.0|\n",
      "|    -4.0|      0.0|\n",
      "|    18.0|      2.0|\n",
      "|     0.0|      1.0|\n",
      "|     0.0|      1.0|\n",
      "|     7.0|      1.0|\n",
      "|    -3.0|      0.0|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[-float(\"inf\"), 0.0, 15.0, float(\"inf\")],\n",
    "                        inputCol='DepDelay', outputCol='SalidaCat')\n",
    "bucketizer.transform(bd5).select('DepDelay','SalidaCat').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versiones más nuevas de Pyspark incluyen otras transformaciones, por ejemplo QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansión polinómica de Variables \n",
    "(términos cuadráticos, productos, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DepDelay=0.0, Distance=1747.0, Polyn=DenseVector([0.0, 0.0, 1747.0, 0.0, 3052009.0])),\n",
       " Row(DepDelay=0.0, Distance=1747.0, Polyn=DenseVector([0.0, 0.0, 1747.0, 0.0, 3052009.0])),\n",
       " Row(DepDelay=-2.0, Distance=1747.0, Polyn=DenseVector([-2.0, 4.0, 1747.0, -3494.0, 3052009.0])),\n",
       " Row(DepDelay=130.0, Distance=628.0, Polyn=DenseVector([130.0, 16900.0, 628.0, 81640.0, 394384.0])),\n",
       " Row(DepDelay=-8.0, Distance=628.0, Polyn=DenseVector([-8.0, 64.0, 628.0, -5024.0, 394384.0]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PolynomialExpansion\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=['DepDelay','Distance'],\n",
    "    outputCol='features')\n",
    "\n",
    "px = PolynomialExpansion(\n",
    "    degree=2, \n",
    "    inputCol=\"features\", \n",
    "    outputCol=\"Polyn\")\n",
    "\n",
    "bd6 = px.transform(assembler.transform(bd5))\n",
    "\n",
    "bd6.select('DepDelay','Distance','Polyn').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estandarización de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|     features|         stdfeatures|\n",
      "+-------------+--------------------+\n",
      "| [0.0,1747.0]|[-0.3455994145866...|\n",
      "| [0.0,1747.0]|[-0.3455994145866...|\n",
      "|[-2.0,1747.0]|[-0.3857378410949...|\n",
      "|[130.0,628.0]|[2.26339830845110...|\n",
      "| [-8.0,628.0]|[-0.5061531206197...|\n",
      "|  [2.0,628.0]|[-0.3054609880783...|\n",
      "| [11.0,628.0]|[-0.1248380687911...|\n",
      "|[-2.0,1199.0]|[-0.3857378410949...|\n",
      "|[-3.0,1199.0]|[-0.4058070543490...|\n",
      "|[-3.0,1747.0]|[-0.4058070543490...|\n",
      "| [2.0,1747.0]|[-0.3054609880783...|\n",
      "|[-4.0,1946.0]|[-0.4258762676032...|\n",
      "| [1.0,1946.0]|[-0.3255302013325...|\n",
      "| [6.0,1587.0]|[-0.2251841350618...|\n",
      "|[-4.0,1587.0]|[-0.4258762676032...|\n",
      "|[18.0,1199.0]|[0.01564642398779...|\n",
      "| [0.0,1199.0]|[-0.3455994145866...|\n",
      "|  [0.0,628.0]|[-0.3455994145866...|\n",
      "|  [7.0,628.0]|[-0.2051149218077...|\n",
      "| [-3.0,628.0]|[-0.4058070543490...|\n",
      "+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"stdfeatures\",\n",
    "                        withStd=True, withMean=True)\n",
    "scalerModel = scaler.fit(bd6)\n",
    "bd6std = scalerModel.transform(bd6)\n",
    "\n",
    "bd6std.select('features','stdfeatures').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tranformación manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bd7 = bd6.withColumn('DepDelay2',(bd6.DepDelay**2)\n",
    ").withColumn('DepD_Distance',(bd6.DepDelay * bd6.Distance)) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
