{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones avanzadas con DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset, obtenido de <a target = \"_blank\" href=\"https://www.transtats.bts.gov/Fields.asp?Table_ID=236\">este link</a> está compuesto por las siguientes variables referidas siempre al año 2018:\n",
    "\n",
    "1. **Month** 1-4\n",
    "2. **DayofMonth** 1-31\n",
    "3. **DayOfWeek** 1 (Monday) - 7 (Sunday)\n",
    "4. **FlightDate** fecha del vuelo\n",
    "5. **Origin** código IATA del aeropuerto de origen\n",
    "6. **OriginCity** ciudad donde está el aeropuerto de origen\n",
    "7. **Dest** código IATA del aeropuerto de destino\n",
    "8. **DestCity** ciudad donde está el aeropuerto de destino  \n",
    "9. **DepTime** hora real de salida (local, hhmm)\n",
    "10. **DepDelay** retraso a la salida, en minutos\n",
    "11. **ArrTime** hora real de llegada (local, hhmm)\n",
    "12. **ArrDelay** retraso a la llegada, en minutos: se considera que un vuelo ha llegado \"on time\" si aterrizó menos de 15 minutos más tarde de la hora prevista en el Computerized Reservations Systems (CRS).\n",
    "13. **Cancelled** si el vuelo fue cancelado (1 = sí, 0 = no)\n",
    "14. **CancellationCode** razón de cancelación (A = aparato, B = tiempo atmosférico, C = NAS, D = seguridad)\n",
    "15. **Diverted** si el vuelo ha sido desviado (1 = sí, 0 = no)\n",
    "16. **ActualElapsedTime** tiempo real invertido en el vuelo\n",
    "17. **AirTime** en minutos\n",
    "18. **Distance** en millas\n",
    "19. **CarrierDelay** en minutos: El retraso del transportista está bajo el control del transportista aéreo. Ejemplos de sucesos que pueden determinar el retraso del transportista son: limpieza de la aeronave, daño de la aeronave, espera de la llegada de los pasajeros o la tripulación de conexión, equipaje, impacto de un pájaro, carga de equipaje, servicio de comidas, computadora, equipo del transportista, problemas legales de la tripulación (descanso del piloto o acompañante) , daños por mercancías peligrosas, inspección de ingeniería, abastecimiento de combustible, pasajeros discapacitados, tripulación retrasada, servicio de inodoros, mantenimiento, ventas excesivas, servicio de agua potable, denegación de viaje a pasajeros en mal estado, proceso de embarque muy lento, equipaje de mano no válido, retrasos de peso y equilibrio.\n",
    "20. **WeatherDelay** en minutos: causado por condiciones atmosféricas extremas o peligrosas, previstas o que se han manifestado antes del despegue, durante el viaje, o a la llegada.\n",
    "21. **NASDelay** en minutos: retraso causado por el National Airspace System (NAS) por motivos como condiciones meteorológicas (perjudiciales pero no extremas), operaciones del aeropuerto, mucho tráfico aéreo, problemas con los controladores aéreos, etc.\n",
    "22. **SecurityDelay** en minutos: causado por la evacuación de una terminal, re-embarque de un avión debido a brechas en la seguridad, fallos en dispositivos del control de seguridad, colas demasiado largas en el control de seguridad, etc.\n",
    "23. **LateAircraftDelay** en minutos: debido al propio retraso del avión al llegar, problemas para conseguir aterrizar en un aeropuerto a una hora más tardía de la que estaba prevista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Tema3\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Leemos los datos y quitamos filas con NA y convertimos a numéricas las columnas inferidas incorrectamente\n",
    "flightsDF = spark.read\\\n",
    "                 .option(\"header\", \"true\")\\\n",
    "                 .option(\"inferSchema\", \"true\")\\\n",
    "                 .csv(\"Datasets/flights-jan-apr-2018.csv\")\n",
    "\n",
    "# Convertimos a enteros y re-categorizamos ArrDelay en una nueva columna ArrDelayCat\n",
    "# None (< 15 min), Slight(entre 15 y 60 min), Huge (> 60 min)\n",
    "\n",
    "cleanFlightsDF = flightsDF.withColumn(\"ArrDelayCat\", F.when(F.col(\"ArrDelay\") < 15, \"None\")\\\n",
    "                                                      .when((F.col(\"ArrDelay\") >= 15) & (F.col(\"ArrDelay\") < 60), \"Slight\")\\\n",
    "                                                      .otherwise(\"Huge\"))\\\n",
    "                           .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hagamos algunas preguntas a los datos para obtener conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos que somos los dueños de una web de viajes que rastrea internet en busca de vuelos en agencias y otras páginas, los compara y recomienda el más adecuado para el aeropuerto. Junto con esta recomendación, querríamos dar también información sobre vuelos fiables y no fiables en lo que respecta a la puntualidad. Esto depende de muchos factores, como el origen y destino, duración del vuelo, hora del día, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupación y agregaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<p><b>PREGUNTA</b>: ¿Cuáles son los vuelos (origen, destino) con mayor retraso medio? ¿Cuántos vuelos existen entre cada par de aeropuertos?</p>\n",
    "<p><b>PISTA</b>: Tras hacer las agregaciones para cada pareja \"Origin\", \"Dest\" (una agregación para el retraso medio y otra para contar), aplica el método sort(F.col(\"avgDelay\").desc()) para ordenar de forma decreciente por la nueva columna del retraso medio.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+------------------+-----+\n",
      "|Origin|Dest|          avgDelay|count|\n",
      "+------+----+------------------+-----+\n",
      "|   RDM| MFR|            1347.0|    2|\n",
      "|   MDT| HPN|             798.0|    1|\n",
      "|   ORD| GTF|             212.0|    1|\n",
      "|   ICT| DAY|             210.0|    1|\n",
      "|   ELM| ATL|             169.0|    2|\n",
      "|   DSM| PIA|             168.0|    1|\n",
      "|   ERI| ITH|             160.0|    1|\n",
      "|   YNG| PIE|             141.0|    1|\n",
      "|   CMH| HOU|             120.0|    1|\n",
      "|   HRL| DAL|             111.0|    1|\n",
      "|   PPG| HNL|109.85714285714286|   35|\n",
      "|   HNL| PPG|105.85714285714286|   35|\n",
      "|   PIE| YNG|             104.0|    1|\n",
      "|   AVP| SFB|              93.0|    1|\n",
      "|   ACY| MSY| 87.45454545454545|   11|\n",
      "|   CPR| LAS|              85.0|    1|\n",
      "|   LAS| CPR|              82.0|    1|\n",
      "|   TTN| BNA|              76.5|   10|\n",
      "|   MSP| PVD|              74.0|    1|\n",
      "|   TUL| OKC|              69.0|    1|\n",
      "+------+----+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FlightsDelayedDF = cleanFlightsDF.groupBy(\"Origin\",\"Dest\")\\\n",
    "                                 .agg(\n",
    "                                        F.mean(\"ArrDelay\").alias(\"avgDelay\"),\\\n",
    "                                        F.count(\"*\").alias(\"count\"))\\\n",
    "                                 .sort(F.col(\"avgDelay\").desc())\n",
    "FlightsDelayedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-------------+--------------+\n",
      "|Origin|Dest|Average_delay|Number_flights|\n",
      "+------+----+-------------+--------------+\n",
      "|   RDM| MFR|       1347.0|             2|\n",
      "|   MDT| HPN|        798.0|             1|\n",
      "|   ORD| GTF|        212.0|             1|\n",
      "|   ICT| DAY|        210.0|             1|\n",
      "|   ELM| ATL|        169.0|             2|\n",
      "|   DSM| PIA|        168.0|             1|\n",
      "|   ERI| ITH|        160.0|             1|\n",
      "|   YNG| PIE|        141.0|             1|\n",
      "|   CMH| HOU|        120.0|             1|\n",
      "|   HRL| DAL|        111.0|             1|\n",
      "|   PPG| HNL|        109.9|            35|\n",
      "|   HNL| PPG|        105.9|            35|\n",
      "|   PIE| YNG|        104.0|             1|\n",
      "|   AVP| SFB|         93.0|             1|\n",
      "|   ACY| MSY|         87.5|            11|\n",
      "|   CPR| LAS|         85.0|             1|\n",
      "|   LAS| CPR|         82.0|             1|\n",
      "|   TTN| BNA|         76.5|            10|\n",
      "|   MSP| PVD|         74.0|             1|\n",
      "|   TUL| OKC|         69.0|             1|\n",
      "+------+----+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AggFlights = cleanFlightsDF.groupBy(F.col(\"Origin\"), F.col(\"Dest\")).agg(\n",
    "                F.round(F.mean(F.col(\"ArrDelay\")),1).alias(\"Average_delay\"),\n",
    "                F.count(\"*\").alias(\"Number_flights\"))\\\n",
    "            .orderBy(F.col(\"Average_delay\"), ascending = False)\n",
    "    \n",
    "AggFlights.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+-------+\n",
      "|Origin|Dest|avgDelay|cuantos|\n",
      "+------+----+--------+-------+\n",
      "|   RDM| MFR|  1347.0|      2|\n",
      "|   MDT| HPN|   798.0|      1|\n",
      "|   ORD| GTF|   212.0|      1|\n",
      "|   ICT| DAY|   210.0|      1|\n",
      "|   ELM| ATL|   169.0|      2|\n",
      "|   DSM| PIA|   168.0|      1|\n",
      "|   ERI| ITH|   160.0|      1|\n",
      "|   YNG| PIE|   141.0|      1|\n",
      "|   CMH| HOU|   120.0|      1|\n",
      "|   HRL| DAL|   111.0|      1|\n",
      "|   PPG| HNL|  109.86|     35|\n",
      "|   HNL| PPG|  105.86|     35|\n",
      "|   PIE| YNG|   104.0|      1|\n",
      "|   AVP| SFB|    93.0|      1|\n",
      "|   ACY| MSY|   87.45|     11|\n",
      "|   CPR| LAS|    85.0|      1|\n",
      "|   LAS| CPR|    82.0|      1|\n",
      "|   TTN| BNA|    76.5|     10|\n",
      "|   MSP| PVD|    74.0|      1|\n",
      "|   TUL| OKC|    69.0|      1|\n",
      "+------+----+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortedAvgDelaysDF = cleanFlightsDF.groupBy(\"Origin\", \"Dest\").agg(\n",
    "                                        F.round(F.mean(\"ArrDelay\"), 2).alias(\"avgDelay\"),\n",
    "                                        F.round(F.count(\"*\"), 2).alias(\"cuantos\")\n",
    "                                    ).sort(\"avgDelay\", ascending = False)\n",
    "\n",
    "sortedAvgDelaysDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+-------+\n",
      "|Origin|Dest|ArrDelayCat|cuantos|\n",
      "+------+----+-----------+-------+\n",
      "|   MCI| MKE|       Huge|      8|\n",
      "|   MCI| MKE|       None|    172|\n",
      "|   MCI| MKE|     Slight|     18|\n",
      "+------+----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortedAvgDelaysDF = cleanFlightsDF.groupBy(\"Origin\", \"Dest\", \"ArrDelayCat\").agg(\n",
    "                                        F.count(\"*\").alias(\"cuantos\"))\\\n",
    "                                    .where(\"Origin = 'MCI' and Dest = 'MKE'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a desplegar ArrDelayCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+----+------+\n",
      "|Origin|Dest|Huge|None|Slight|\n",
      "+------+----+----+----+------+\n",
      "|   MCI| MKE|   8| 172|    18|\n",
      "|   TPA| ACY|   4| 112|     4|\n",
      "|   PBI| DCA|  37| 393|    49|\n",
      "|   DSM| EWR|  10|  94|    14|\n",
      "|   MDW| MEM|  22| 172|    42|\n",
      "|   ORD| PDX|  23| 528|    85|\n",
      "|   SHD| LWB|   2|  25|  null|\n",
      "|   SMF| BUR|  61| 720|   124|\n",
      "|   STS| PHX|   9| 105|    14|\n",
      "|   MCI| IAH|  38| 487|    54|\n",
      "|   FSD| ATL|   9|  83|     9|\n",
      "|   PHL| MCO| 162|1291|   273|\n",
      "|   ATL| GSP|  47|1080|   106|\n",
      "|   SJC| LIH|   1|  83|     5|\n",
      "|   DSM| MCO|   1|  30|    10|\n",
      "|   IAD| ILM|   2|  34|     8|\n",
      "|   PBG| PGD|   1|  19|     6|\n",
      "|   LBB| DEN|  20| 184|    20|\n",
      "|   SNA| PHX|  57| 967|   256|\n",
      "|   PIE| AVP|null|   1|  null|\n",
      "+------+----+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sortedAvgDelaysDF = cleanFlightsDF.groupBy(\"Origin\", \"Dest\").pivot(\"ArrDelayCat\").agg(\n",
    "                                        F.count(\"*\").alias(\"cuantos\")\n",
    ")\n",
    "sortedAvgDelaysDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+------+\n",
      "|Origin|Huge| None|Slight|\n",
      "+------+----+-----+------+\n",
      "|   BGM|  32|  223|    27|\n",
      "|   PSE|  26|  194|    27|\n",
      "|   INL|  21|  172|    14|\n",
      "|   PPG|   4|   21|    10|\n",
      "|   MSY|1298|15297|  2262|\n",
      "|   GEG| 207| 5836|   596|\n",
      "|   SNA| 705|12038|  1464|\n",
      "|   BUR| 637| 7025|  1253|\n",
      "|   GRB| 173| 1441|   180|\n",
      "|   GTF|  59|  731|    86|\n",
      "|   IFP|null|   31|    14|\n",
      "|   IDA|  32|  699|    61|\n",
      "|   LWB|   5|   43|    10|\n",
      "|   GRR| 667| 5068|   863|\n",
      "|   PVU|  14|  133|    22|\n",
      "|   JLN|  27|  197|    53|\n",
      "|   EUG| 157| 2360|   261|\n",
      "|   PSG|  12|  211|    17|\n",
      "|   GSO| 528| 4011|   623|\n",
      "|   MYR| 262| 2335|   290|\n",
      "+------+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanFlightsDF.groupBy(\"Origin\")\\\n",
    "              .pivot(\"ArrDelayCat\")\\\n",
    "              .count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<p><b>PREGUNTA</b>: ¿Es el avión un medio de transporte fiable? Mostrar el número de vuelos en cada categoría de retraso.</p>\n",
    "En lugar de llamar agg(F.count(\"*\")), podemos llamar a la transformación count() sobre el resultado de groupBy(), y creará\n",
    "automáticamente una columna llamada \"count\" con los conteos para cada grupo.\n",
    "<p> Ahora agrupar también por cada aeropuerto de origen, y mostrando una columna distinta por cada tipo de retraso, con el recuento. PISTA: utilizar la función pivot(\"colName\").</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------------+-----------+----------------+-------------+------------------+\n",
      "|Origin|Huge_Conteo|Huge_maxArrDelay|None_Conteo|None_maxArrDelay|Slight_Conteo|Slight_maxArrDelay|\n",
      "+------+-----------+----------------+-----------+----------------+-------------+------------------+\n",
      "|   ABE|        193|           674.0|       1230|            14.0|          239|              59.0|\n",
      "|   ABI|         56|           397.0|        497|            14.0|           76|              59.0|\n",
      "|   ABQ|        457|          1650.0|       7184|            14.0|          947|              59.0|\n",
      "|   ABR|         22|           584.0|        198|            13.0|           20|              40.0|\n",
      "|   ABY|         38|           641.0|        239|            14.0|           57|              50.0|\n",
      "|   ACT|         40|           500.0|        386|            14.0|           42|              59.0|\n",
      "|   ACV|         40|           900.0|        291|            14.0|           33|              59.0|\n",
      "|   ACY|         78|          1385.0|       1002|            14.0|           92|              58.0|\n",
      "|   ADK|          4|           196.0|         25|            11.0|            5|              48.0|\n",
      "|   ADQ|         12|           221.0|        178|            14.0|           15|              55.0|\n",
      "|   AEX|         81|          1033.0|        904|            14.0|          119|              58.0|\n",
      "|   AGS|        136|          1366.0|       1343|            14.0|          237|              58.0|\n",
      "|   ALB|        560|          1107.0|       4274|            14.0|          712|              59.0|\n",
      "|   ALO|         20|           435.0|        174|            14.0|           29|              56.0|\n",
      "|   ALW|         14|           175.0|        280|            14.0|           25|              58.0|\n",
      "|   AMA|        120|           518.0|       1552|            14.0|          163|              59.0|\n",
      "|   ANC|        246|          1064.0|       4803|            14.0|          466|              59.0|\n",
      "|   APN|         36|           469.0|        150|            13.0|           19|              47.0|\n",
      "|   ART|         74|          1149.0|        151|            10.0|           15|              57.0|\n",
      "|   ASE|        601|          1383.0|       2414|            14.0|          348|              59.0|\n",
      "+------+-----------+----------------+-----------+----------------+-------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pivot = cleanFlightsDF.groupBy(\"Origin\")\\\n",
    "                      .pivot(\"ArrDelayCat\").agg(\n",
    "                          F.count(\"*\").alias(\"Conteo\"),\n",
    "                          F.max(\"ArrDelay\").alias(\"maxArrDelay\"))\\\n",
    "                        .sort(\"Origin\")\n",
    "pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "averageDelayOriginDestDF = cleanFlightsDF.groupBy(\"Origin\", \"Dest\").agg(\n",
    "    F.mean(\"ArrDelay\").alias(\"avgArrDelay\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------------------+----------+-------------------+------------+------------------+\n",
      "|Origin|Dest|Huge_count|     Huge_avgDelay|None_count|      None_avgDelay|Slight_count|   Slight_avgDelay|\n",
      "+------+----+----------+------------------+----------+-------------------+------------+------------------+\n",
      "|   MCI| MKE|         8|              89.5|       172| -8.325581395348838|          18|31.166666666666668|\n",
      "|   TPA| ACY|         4|              79.0|       112| -9.857142857142858|           4|              27.0|\n",
      "|   PBI| DCA|        37|127.38461538461539|       393|-13.061068702290076|          49| 33.42857142857143|\n",
      "|   DSM| EWR|        10|             121.8|        94|-12.085106382978724|          14|29.714285714285715|\n",
      "|   MDW| MEM|        22|102.33333333333333|       172| -9.087209302325581|          42|33.095238095238095|\n",
      "|   ORD| PDX|        23| 102.0952380952381|       528| -8.910984848484848|          85|29.141176470588235|\n",
      "|   SHD| LWB|         2|             368.0|        25|              -3.08|        null|              null|\n",
      "|   SMF| BUR|        61|109.28260869565217|       720|            -3.6625|         124|31.217741935483872|\n",
      "|   STS| PHX|         9|             289.5|       105|              -11.4|          14|              35.5|\n",
      "|   MCI| IAH|        38|168.76923076923077|       487|-14.234086242299794|          54|31.166666666666668|\n",
      "|   FSD| ATL|         9|324.14285714285717|        83|              -18.0|           9|36.333333333333336|\n",
      "|   PHL| MCO|       162|            132.65|      1291| -8.792408985282727|         273|29.663003663003664|\n",
      "|   ATL| GSP|        47|             106.7|      1080| -8.875925925925927|         106| 30.10377358490566|\n",
      "|   SJC| LIH|         1|             152.0|        83|-15.759036144578314|           5|              26.2|\n",
      "|   DSM| MCO|         1|             226.0|        30| -6.266666666666667|          10|              34.6|\n",
      "|   IAD| ILM|         2|             100.5|        34|-2.9411764705882355|           8|             27.25|\n",
      "|   PBG| PGD|         1|             484.0|        19|-10.578947368421053|           6|25.166666666666668|\n",
      "|   LBB| DEN|        20|           171.375|       184|-11.570652173913043|          20|             28.35|\n",
      "|   SNA| PHX|        57| 94.68518518518519|       967| -4.402275077559462|         256|        28.9921875|\n",
      "|   PIE| AVP|      null|              null|         1|               -1.0|        null|              null|\n",
      "+------+----+----------+------------------+----------+-------------------+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanFlightsDF.groupBy(\"Origin\", \"Dest\").pivot(\"ArrDelayCat\").agg(\n",
    "        F.count(\"*\").alias(\"count\"),\n",
    "        F.mean(\"ArrDelay\").alias(\"avgDelay\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<p><b>PREGUNTA</b>: ¿Hay relación entre el día de la semana y el retraso a la salida o a la llegada?</p>\n",
    "    <p><b>PISTA</b>: Calcula el retraso medio a la salida y a la llegada para cada día de la semana y ordena por una de ellas descendentemente.</p>\n",
    "    <p> Ahora haz lo mismo para cada día pero solo con el retraso a la llegada, desagregado por cada aeropuerto de salida, utilizando la función pivot(). </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p><b>LA FUNCIÓN PIVOT</b>: Puede ser interesante ver, para cada (Origin, Dest), el retraso promedio por\n",
    "día de la semana. Si agrupamos por esas tres variables (Origin, Dest, DayOfWeek), nuestro resultado tendría demasiadas filas para ser fácil de visualizar (7 x 1009 ya que hay 1009 combinaciones de (Origin, DayOfWeek)). En cambio, vamos a crear 7 columnas, una por día de la semana, en nuestro resultado DF. Lo haremos utilizando una de las variables de agrupación (DayOfWeek) como <i> variable pivot</i>. Como esta variable tiene 7 valores distintos, se crearán 7 columnas nuevas. De esta manera, visualizaremos toda la información de cada combinación (Origen, Dest) condensada en una fila con 7 columnas con los 7 retrasos promedio correspondientes a ese (Origen, Dest) en cada día de la semana.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------------+\n",
      "|DayOfWeek|        avgArrDelay|       avgDepDelay|\n",
      "+---------+-------------------+------------------+\n",
      "|        1|  5.391113068725289|10.430177708665964|\n",
      "|        2| 2.8412409647873806| 8.246502522185226|\n",
      "|        3| 3.0525338339576717|  8.47071347600168|\n",
      "|        4| 2.7390527404801026|  8.35856546210902|\n",
      "|        5|  5.027363815430113|10.220785437977693|\n",
      "|        6|-0.5748593305876211| 6.278199328016013|\n",
      "|        7| 3.2344449424598207| 9.142161259888235|\n",
      "+---------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgDelaysDF = flightsDF.groupBy(\"DayOfWeek\").agg(\n",
    "    F.mean(\"ArrDelay\").alias(\"avgArrDelay\"),\n",
    "    F.mean(\"DepDelay\").alias(\"avgDepDelay\")\n",
    ").sort(\"DayOfWeek\")\n",
    "avgDelaysDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuando utilizo pivot con una sola función de agregación, el alias es ignorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABE</td>\n",
       "      <td>14.953307</td>\n",
       "      <td>13.893519</td>\n",
       "      <td>15.276786</td>\n",
       "      <td>5.924370</td>\n",
       "      <td>18.183333</td>\n",
       "      <td>6.940299</td>\n",
       "      <td>10.027149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>16.364706</td>\n",
       "      <td>-0.547619</td>\n",
       "      <td>0.376344</td>\n",
       "      <td>4.641304</td>\n",
       "      <td>16.492063</td>\n",
       "      <td>4.606383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ</td>\n",
       "      <td>1.442438</td>\n",
       "      <td>0.363406</td>\n",
       "      <td>1.736409</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>-0.176892</td>\n",
       "      <td>-1.655721</td>\n",
       "      <td>-0.252019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABR</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>12.468750</td>\n",
       "      <td>6.294118</td>\n",
       "      <td>16.441176</td>\n",
       "      <td>8.529412</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>9.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABY</td>\n",
       "      <td>14.207547</td>\n",
       "      <td>3.978723</td>\n",
       "      <td>12.804348</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>9.040816</td>\n",
       "      <td>29.562500</td>\n",
       "      <td>27.234043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>XNA</td>\n",
       "      <td>9.592857</td>\n",
       "      <td>9.375580</td>\n",
       "      <td>6.838462</td>\n",
       "      <td>1.854015</td>\n",
       "      <td>3.877941</td>\n",
       "      <td>-0.977208</td>\n",
       "      <td>5.438861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>YAK</td>\n",
       "      <td>-9.451613</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-10.727273</td>\n",
       "      <td>2.848485</td>\n",
       "      <td>-9.470588</td>\n",
       "      <td>-12.088235</td>\n",
       "      <td>-10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>YKM</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>-0.490909</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>6.269841</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>1.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>YNG</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>YUM</td>\n",
       "      <td>-6.819444</td>\n",
       "      <td>-8.661290</td>\n",
       "      <td>-1.588235</td>\n",
       "      <td>-4.447761</td>\n",
       "      <td>-9.088235</td>\n",
       "      <td>-12.028986</td>\n",
       "      <td>-9.367647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Origin          1          2          3           4          5          6  \\\n",
       "0      ABE  14.953307  13.893519  15.276786    5.924370  18.183333   6.940299   \n",
       "1      ABI  10.650000  16.364706  -0.547619    0.376344   4.641304  16.492063   \n",
       "2      ABQ   1.442438   0.363406   1.736409    3.111111  -0.176892  -1.655721   \n",
       "3      ABR  10.571429  12.468750   6.294118   16.441176   8.529412   0.125000   \n",
       "4      ABY  14.207547   3.978723  12.804348   10.645833   9.040816  29.562500   \n",
       "..     ...        ...        ...        ...         ...        ...        ...   \n",
       "351    XNA   9.592857   9.375580   6.838462    1.854015   3.877941  -0.977208   \n",
       "352    YAK  -9.451613 -13.000000 -10.727273    2.848485  -9.470588 -12.088235   \n",
       "353    YKM   0.338462  -0.490909   5.666667    1.359375   6.269841   5.941176   \n",
       "354    YNG   9.000000        NaN        NaN  141.000000        NaN        NaN   \n",
       "355    YUM  -6.819444  -8.661290  -1.588235   -4.447761  -9.088235 -12.028986   \n",
       "\n",
       "             7  \n",
       "0    10.027149  \n",
       "1     4.606383  \n",
       "2    -0.252019  \n",
       "3     9.117647  \n",
       "4    27.234043  \n",
       "..         ...  \n",
       "351   5.438861  \n",
       "352 -10.090909  \n",
       "353   1.603175  \n",
       "354        NaN  \n",
       "355  -9.367647  \n",
       "\n",
       "[356 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsPd = flightsDF.groupby(\"Origin\").pivot(\"DayOfWeek\").agg(\n",
    "    F.mean(\"ArrDelay\").alias(\"MeanArrDelay\")\n",
    ").sort(\"Origin\").toPandas()\n",
    "\n",
    "flightsPd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pero cuando utilizo varias funciones de agregación, entonces sí es necesario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark concatena con \"_\" cada valor de la variable pivotada con mis alias de las func de agregación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origin</th>\n",
       "      <th>1_MeanArrDelay</th>\n",
       "      <th>1_MinArrDelay</th>\n",
       "      <th>2_MeanArrDelay</th>\n",
       "      <th>2_MinArrDelay</th>\n",
       "      <th>3_MeanArrDelay</th>\n",
       "      <th>3_MinArrDelay</th>\n",
       "      <th>4_MeanArrDelay</th>\n",
       "      <th>4_MinArrDelay</th>\n",
       "      <th>5_MeanArrDelay</th>\n",
       "      <th>5_MinArrDelay</th>\n",
       "      <th>6_MeanArrDelay</th>\n",
       "      <th>6_MinArrDelay</th>\n",
       "      <th>7_MeanArrDelay</th>\n",
       "      <th>7_MinArrDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABE</td>\n",
       "      <td>14.953307</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>13.893519</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>15.276786</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>5.924370</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>18.183333</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>6.940299</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>10.027149</td>\n",
       "      <td>-36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABI</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>16.364706</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-0.547619</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0.376344</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>4.641304</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>16.492063</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>4.606383</td>\n",
       "      <td>-28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABQ</td>\n",
       "      <td>1.442438</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>0.363406</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>1.736409</td>\n",
       "      <td>-67.0</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>-61.0</td>\n",
       "      <td>-0.176892</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>-1.655721</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-0.252019</td>\n",
       "      <td>-59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABR</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>12.468750</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>6.294118</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>16.441176</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>8.529412</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>9.117647</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABY</td>\n",
       "      <td>14.207547</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>3.978723</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>12.804348</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>10.645833</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>9.040816</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>29.562500</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>27.234043</td>\n",
       "      <td>-31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>XNA</td>\n",
       "      <td>9.592857</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>9.375580</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>6.838462</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>1.854015</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>3.877941</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-0.977208</td>\n",
       "      <td>-51.0</td>\n",
       "      <td>5.438861</td>\n",
       "      <td>-41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>YAK</td>\n",
       "      <td>-9.451613</td>\n",
       "      <td>-45.0</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-10.727273</td>\n",
       "      <td>-46.0</td>\n",
       "      <td>2.848485</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-9.470588</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-12.088235</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-10.090909</td>\n",
       "      <td>-41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>YKM</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-0.490909</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>1.359375</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>6.269841</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>1.603175</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>YNG</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>YUM</td>\n",
       "      <td>-6.819444</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-8.661290</td>\n",
       "      <td>-47.0</td>\n",
       "      <td>-1.588235</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>-4.447761</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-9.088235</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>-12.028986</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>-9.367647</td>\n",
       "      <td>-36.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Origin  1_MeanArrDelay  1_MinArrDelay  2_MeanArrDelay  2_MinArrDelay  \\\n",
       "0      ABE       14.953307          -41.0       13.893519          -32.0   \n",
       "1      ABI       10.650000          -28.0       16.364706          -27.0   \n",
       "2      ABQ        1.442438          -67.0        0.363406          -61.0   \n",
       "3      ABR       10.571429          -27.0       12.468750          -33.0   \n",
       "4      ABY       14.207547          -34.0        3.978723          -34.0   \n",
       "..     ...             ...            ...             ...            ...   \n",
       "351    XNA        9.592857          -39.0        9.375580          -46.0   \n",
       "352    YAK       -9.451613          -45.0      -13.000000          -41.0   \n",
       "353    YKM        0.338462          -16.0       -0.490909          -21.0   \n",
       "354    YNG        9.000000            9.0             NaN            NaN   \n",
       "355    YUM       -6.819444          -39.0       -8.661290          -47.0   \n",
       "\n",
       "     3_MeanArrDelay  3_MinArrDelay  4_MeanArrDelay  4_MinArrDelay  \\\n",
       "0         15.276786          -34.0        5.924370          -42.0   \n",
       "1         -0.547619          -23.0        0.376344          -22.0   \n",
       "2          1.736409          -67.0        3.111111          -61.0   \n",
       "3          6.294118          -31.0       16.441176          -28.0   \n",
       "4         12.804348          -20.0       10.645833          -25.0   \n",
       "..              ...            ...             ...            ...   \n",
       "351        6.838462          -49.0        1.854015          -43.0   \n",
       "352      -10.727273          -46.0        2.848485          -34.0   \n",
       "353        5.666667          -28.0        1.359375          -18.0   \n",
       "354             NaN            NaN      141.000000          141.0   \n",
       "355       -1.588235          -44.0       -4.447761          -50.0   \n",
       "\n",
       "     5_MeanArrDelay  5_MinArrDelay  6_MeanArrDelay  6_MinArrDelay  \\\n",
       "0         18.183333          -37.0        6.940299          -33.0   \n",
       "1          4.641304          -27.0       16.492063          -23.0   \n",
       "2         -0.176892          -52.0       -1.655721          -63.0   \n",
       "3          8.529412          -29.0        0.125000          -31.0   \n",
       "4          9.040816          -21.0       29.562500          -17.0   \n",
       "..              ...            ...             ...            ...   \n",
       "351        3.877941          -50.0       -0.977208          -51.0   \n",
       "352       -9.470588          -36.0      -12.088235          -50.0   \n",
       "353        6.269841          -18.0        5.941176          -21.0   \n",
       "354             NaN            NaN             NaN            NaN   \n",
       "355       -9.088235          -41.0      -12.028986          -42.0   \n",
       "\n",
       "     7_MeanArrDelay  7_MinArrDelay  \n",
       "0         10.027149          -36.0  \n",
       "1          4.606383          -28.0  \n",
       "2         -0.252019          -59.0  \n",
       "3          9.117647          -30.0  \n",
       "4         27.234043          -31.0  \n",
       "..              ...            ...  \n",
       "351        5.438861          -41.0  \n",
       "352      -10.090909          -41.0  \n",
       "353        1.603175          -30.0  \n",
       "354             NaN            NaN  \n",
       "355       -9.367647          -36.0  \n",
       "\n",
       "[356 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightsDF.groupby(\"Origin\").pivot(\"DayOfWeek\").agg(\n",
    "    F.mean(\"ArrDelay\").alias(\"MeanArrDelay\"),\n",
    "    F.min(\"ArrDelay\").alias(\"MinArrDelay\")\n",
    "    ).sort(\"Origin\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones JOIN y de ventana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estaría bien tener el retraso promedio de una ruta junto a cada vuelo, para que podamos ver qué vuelos tuvieron un retraso que fue superior o inferior al retraso promedio de esa ruta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b> PREGUNTA </b>:\n",
    "Usa el averageDelayOriginDestDF creado anteriormente, elimina la columna de conteo y luego únerlo con cleanFlightsDF, utilizando Origin y Dest como columnas de enlace. Finalmente, selecciona solo las columnas Origin, Dest, DayOfWeek, ArrDelay y avgDelay del resultado.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column Origin#20, Dest#22 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-456230b2b1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tempDF = cleanFlightsDF.join(averageDelayOriginDestDF, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcleanFlightsDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Origin\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maverageDelayOriginDestDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Origin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0;34m(\u001b[0m\u001b[0mcleanFlightsDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dest\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maverageDelayOriginDestDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dest\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             )\\\n\u001b[1;32m      5\u001b[0m                          \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanFlightsDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Origin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcleanFlightsDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dest\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DayOfWeek\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ArrDelay\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avgArrDelay\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1667\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m         \"\"\"\n\u001b[0;32m-> 1669\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column Origin#20, Dest#22 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
     ]
    }
   ],
   "source": [
    "tempDF = cleanFlightsDF.join(averageDelayOriginDestDF, \n",
    "                               on = (cleanFlightsDF[\"Origin\"] == averageDelayOriginDestDF[\"Origin\"]) & \n",
    "                                    (cleanFlightsDF[\"Dest\"] == averageDelayOriginDestDF[\"Dest\"])\n",
    "                            )\\\n",
    "                         .select(cleanFlightsDF[\"Origin\"], cleanFlightsDF[\"Dest\"], \"DayOfWeek\", \"ArrDelay\", \"avgArrDelay\")\n",
    "\n",
    "tempDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+--------+------------------+\n",
      "|Origin|Dest|DayOfWeek|ArrDelay|          avgDelay|\n",
      "+------+----+---------+--------+------------------+\n",
      "|   ATL| GSP|        3|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        3|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        3|    47.0|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    null|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    38.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|   -13.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|   -15.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|   -14.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    14.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|   -22.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|\n",
      "|   ATL| GSP|        7|   -16.0|-1.734910277324633|\n",
      "|   ATL| GSP|        7|    25.0|-1.734910277324633|\n",
      "+------+----+---------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averageDelayOriginDestDF = cleanFlightsDF.groupBy(\"Origin\", \"Dest\")\\\n",
    "                                         .agg(F.mean(\"ArrDelay\").alias(\"avgDelay\"))\n",
    "\n",
    "joinedDF = cleanFlightsDF.join(averageDelayOriginDestDF, \n",
    "                               on = [\"Origin\", \"Dest\"], \n",
    "                               how = \"left_outer\")\\\n",
    "                         .select(\"Origin\", \"Dest\", \"DayOfWeek\", \"ArrDelay\", \"avgDelay\")\n",
    "\n",
    "joinedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+--------+------------------+------------+\n",
      "|Origin|Dest|DayOfWeek|ArrDelay|       avgArrDelay|belowAverage|\n",
      "+------+----+---------+--------+------------------+------------+\n",
      "|   ATL| GSP|        3|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        3|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        3|    47.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|        4|    null|-1.734910277324633|        null|\n",
      "|   ATL| GSP|        4|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        4|    38.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|        1|   -13.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        1|   -15.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|        5|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        5|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        5|   -14.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|        1|    14.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|        1|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        2|   -22.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        7|   -16.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|        7|    25.0|-1.734910277324633|       false|\n",
      "+------+----+---------+--------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window().partitionBy(\"Origin\", \"Dest\")\n",
    "joinedWindowDF = cleanFlightsDF.withColumn(\"avgArrDelay\", F.mean(\"ArrDelay\").over(w))\\\n",
    "                               .select(\"Origin\",\"Dest\",\"DayOfWeek\",\"ArrDelay\",\"avgArrDelay\")\\\n",
    "                               .withColumn(\"belowAverage\", F.col(\"ArrDelay\") < F.col(\"avgArrDelay\"))\n",
    "joinedWindowDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p><b>BONUS (OPCIONAL)</b>: crear una nueva columna <i>belowAverage</i> que tenga valor True si ArrDelay es menor que el avgDelay de esa ruta, y False en caso contrario. No utilizar la función when() sino el operador de comparación directamente entre columnas, la cual devolverá una columna booleana.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA**: repetir la operación utilizando funciones de ventana, sin usar `join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+--------+------------------+\n",
      "|Origin|Dest|DayOfWeek|ArrDelay|          avgDelay|\n",
      "+------+----+---------+--------+------------------+\n",
      "|   ATL| GSP|        3|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        3|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        3|    47.0|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    null|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        4|    38.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|   -13.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|   -15.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|    -6.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        5|   -14.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    10.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    14.0|-1.734910277324633|\n",
      "|   ATL| GSP|        1|    -3.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|   -22.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|\n",
      "|   ATL| GSP|        2|    -9.0|-1.734910277324633|\n",
      "|   ATL| GSP|        7|   -16.0|-1.734910277324633|\n",
      "|   ATL| GSP|        7|    25.0|-1.734910277324633|\n",
      "+------+----+---------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window().partitionBy(\"Origin\", \"Dest\")\n",
    "\n",
    "withAvgDF = cleanFlightsDF.withColumn(\"avgDelay\", F.mean(\"ArrDelay\").over(w))\n",
    "withAvgDF.where(\"Origin = 'ATL' and Dest = 'GSP'\")\\\n",
    "         .select(\"Origin\", \"Dest\", \"DayOfWeek\", \"ArrDelay\", \"avgDelay\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La solución de Cayetano al bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+--------+------------------+------------+\n",
      "|Origin|Dest|ArrDelay|          avgDelay|belowAverage|\n",
      "+------+----+--------+------------------+------------+\n",
      "|   ATL| GSP|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    47.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|    null|-1.734910277324633|       false|\n",
      "|   ATL| GSP|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    38.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|   -13.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|   -15.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    10.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|    -6.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|   -14.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    10.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|    14.0|-1.734910277324633|       false|\n",
      "|   ATL| GSP|    -3.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|   -22.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    -9.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    -9.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|   -16.0|-1.734910277324633|        true|\n",
      "|   ATL| GSP|    25.0|-1.734910277324633|       false|\n",
      "+------+----+--------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bonusDF = withAvgDF.withColumn(\"belowAverage\", \n",
    "                              F.when(F.col(\"ArrDelay\") < F.col(\"avgDelay\"), True).otherwise(False))\n",
    "bonusDF.select(\"Origin\", \"Dest\", \"ArrDelay\", \"avgDelay\", \"belowAverage\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b> PREGUNTA </b>: Vamos a construir otro DF con información sobre los aeropuertos (en una situación real, tendríamos otra tabla en la base de datos como la tabla de la entidad Aeropuerto). Sin embargo, solo tenemos información sobre algunos aeropuertos. Nos gustaría agregar esta información a cleanFlightsDF como nuevas columnas, teniendo en cuenta que queremos que la información del aeropuerto coincida con el aeropuerto de origen de flightsDF. Utilizar la operación de unión adecuada para asegurarse de que no se perderá ninguna de las filas existentes de cleanFlightsDF después de la unión.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inciso: cómo crear un DF de Spark a partir de un dataframe de Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|IATA|Year|\n",
      "+----+----+\n",
      "| JFK|1948|\n",
      "| LIT|1931|\n",
      "| SEA|1949|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "airports_pd = pd.DataFrame({\"IATA\": [\"JFK\", \"LIT\", \"SEA\"],\n",
    "                            \"Year\": [1948, 1931, 1949]})\n",
    "airportsFromPandasDF = spark.createDataFrame(airports_pd)\n",
    "airportsFromPandasDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportsDF = spark.createDataFrame([\n",
    "    (\"JFK\", \"John F. Kennedy International Airport\", 1948),\n",
    "    (\"LIT\", \"Little Rock National Airport\", 1931),\n",
    "    (\"SEA\", \"Seattle-Tacoma International Airport\", 1949),\n",
    "], [\"IATA\", \"FullName\", \"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+------------------------------------+----+\n",
      "|Origin|Dest|IATA|FullName                            |Year|\n",
      "+------+----+----+------------------------------------+----+\n",
      "|SEA   |JFK |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |LGB |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |BOS |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |BOS |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |LGB |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |JFK |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |LGB |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |BOS |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |BOS |SEA |Seattle-Tacoma International Airport|1949|\n",
      "|SEA   |LGB |SEA |Seattle-Tacoma International Airport|1949|\n",
      "+------+----+----+------------------------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleanFlights[\"Origin\"] == airportsDF[\"IATA\"]\n",
    "# F.col(\"Origin\") == airportsDF(\"IATA\")\n",
    "\n",
    "joinedFlightsDF = cleanFlightsDF.join(airportsDF, \n",
    "                                      on = cleanFlightsDF.Origin == airportsDF.IATA, \n",
    "                                      how = \"left_outer\")\n",
    "\n",
    "# PREGUNTA: mostrar algunas filas donde FullName no sea null\n",
    "# equivalente: filter(\"FullName is not null\")\n",
    "joinedFlightsDF.filter(~(F.col(\"FullName\").isNull()))\\\n",
    "               .select(\"Origin\", \"Dest\", \"IATA\", \"FullName\", \"Year\")\\\n",
    "               .show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions (UDFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir un UDF para convertir millas a kilómetros. Ten en cuenta que esto podría hacerse fácilmente multiplicando directamente la columna de millas por 1.6 (y sería mucho más eficiente), ya que Spark permite el producto entre una columna y un número. En todos los casos en los que Spark proporciona funciones integradas para realizar una tarea (como esta), debes usar esas funciones y no una UDF. Las UDF deben emplearse solo cuando no hay otra opción.\n",
    "\n",
    "La razón es que las funciones integradas de Spark están optimizadas y Catalyst, el optimizador automático de código integrado en Spark, puede optimizarlo aún más. Sin embargo, las UDF son una caja negra para Catalyst y su contenido no se optimizará, y por lo tanto, generalmente son mucho más lentas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n",
      "+------+----+--------+------------------+\n",
      "|Origin|Dest|Distance|            DistKM|\n",
      "+------+----+--------+------------------+\n",
      "|   CLE| JFK|   425.0|             680.0|\n",
      "|   MCO| PSE|  1179.0|            1886.4|\n",
      "|   FLL| DTW|  1127.0|            1803.2|\n",
      "|   LAX| MTJ|   666.0|1065.6000000000001|\n",
      "|   AZA| MLI|  1288.0|            2060.8|\n",
      "+------+----+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Primer paso: crear una función de Python que reciba UN número y lo multiplique por 1.6\n",
    "def milesToKm(miles):\n",
    "    return miles*1.6\n",
    "\n",
    "# Vamos a probarla\n",
    "print(milesToKm(5)) # 5 millas a km: 8 km\n",
    "\n",
    "# Segundo paso: crear un objeto UDF que envuelva a nuestra función. \n",
    "# Hay que especificar el tipo de dato que devuelve nuestra función\n",
    "udfMilesToKm = F.udf(milesToKm, DoubleType())\n",
    "\n",
    "# Con esto, Spark será capaz de llamar a nuestra función milesToKm sobre cada uno de los valores de una columna numérica.\n",
    "# Spark enviará el código de nuestra función a los executors a través de la red, y cada executor la ejecutará sobre las\n",
    "# particiones (una por una) que estén en ese executor\n",
    "\n",
    "# Tercer paso: vamos a probar la UDF añadiendo una nueva columna con el resultado de la conversión\n",
    "flightsWithKm = cleanFlightsDF.withColumn(\"DistKm\", udfMilesToKm(F.col(\"Distance\")))\n",
    "\n",
    "flightsWithKm.select(\"Origin\", \"Dest\", \"Distance\", \"DistKM\")\\\n",
    "             .distinct()\\\n",
    "             .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<p><b>BONUS</b>: Crea tu propia UDF que convierta DayOfWeek en una cadena.\n",
    "Puedes hacerlo creando una función de Python que reciba un número entero y devuelva el día de la semana,\n",
    "simplemente leyendo desde un vector de cadenas de longitud 7 el valor en la posición indicada por el argumento entero. Para la UDF, recuerda que tu función devuelve un StringType(). Finalmente, prueba tu UDF creando una nueva columna \"DayOfWeekString\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuesday\n",
      "+------+----+---------+---------------+\n",
      "|Origin|Dest|DayOfWeek|DayOfWeekString|\n",
      "+------+----+---------+---------------+\n",
      "|   BQK| ATL|        4|       Thursday|\n",
      "|   CVG| PHL|        3|      Wednesday|\n",
      "|   DTW| DFW|        5|         Friday|\n",
      "|   SEA| JFK|        2|        Tuesday|\n",
      "|   JAX| JFK|        2|        Tuesday|\n",
      "|   RDU| BOS|        3|      Wednesday|\n",
      "|   SEA| BOS|        3|      Wednesday|\n",
      "|   AUS| FLL|        3|      Wednesday|\n",
      "|   JFK| LAS|        5|         Friday|\n",
      "|   SLC| BOS|        6|       Saturday|\n",
      "|   BOS| HOU|        6|       Saturday|\n",
      "|   BDL| MCO|        7|         Sunday|\n",
      "|   SJU| TPA|        7|         Sunday|\n",
      "|   PGD| TYS|        6|       Saturday|\n",
      "|   PIE| CVG|        6|       Saturday|\n",
      "|   ABE| SFB|        7|         Sunday|\n",
      "|   LAS| BIS|        7|         Sunday|\n",
      "|   ROC| PGD|        1|         Monday|\n",
      "|   EWR| CVG|        1|         Monday|\n",
      "|   CVG| SFB|        1|         Monday|\n",
      "+------+----+---------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Primer paso: creamos una función de python que convierte un número entero en el día de la semana como cadena\n",
    "def dayOfWeekToString(dayInteger):\n",
    "    # En nuestros datos Monday es 1 pero las listas de python empiezan en el 0 y \n",
    "    # queremos usar el dayInteger como índice del vector\n",
    "    daysOfWeek = [\"\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    return daysOfWeek[dayInteger]\n",
    "\n",
    "print(dayOfWeekToString(2))\n",
    "\n",
    "# Segundo paso: ajustamos nuestra función con un Spark UDF para que Spark pueda invocarlo en cada valor de una columna completa\n",
    "# De esta manera, Spark puede enviar nuestra función a los ejecutores, que eventualmente ejecutarán la función en las particiones\n",
    "# de los datos que tiene cada ejecutor\n",
    "dayOfWeekStringUDF = F.udf(dayOfWeekToString, StringType())\n",
    "\n",
    "# Tercer paso: intentemos nuestro UDF agregando una nueva columna que resulta de transformar (a través del UDF) el\n",
    "# columna existente DayOfWeek\n",
    "flightsWithDayOfWeekStr = cleanFlightsDF.withColumn(\"DayOfWeekString\", dayOfWeekStringUDF(F.col(\"DayOfWeek\")))\n",
    "\n",
    "flightsWithDayOfWeekStr.select(\"Origin\", \"Dest\", \"DayOfWeek\", \"DayOfWeekString\")\\\n",
    "                       .distinct()\\\n",
    "                       .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
