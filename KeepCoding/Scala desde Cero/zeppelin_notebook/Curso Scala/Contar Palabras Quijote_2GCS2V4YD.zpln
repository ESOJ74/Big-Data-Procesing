{
  "paragraphs": [
    {
      "text": "import org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.log4j._",
      "user": "anonymous",
      "dateUpdated": "2021-09-16 14:16:41.026",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark._\nimport org.apache.spark.SparkContext._\nimport org.apache.log4j._\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625381734625_869528169",
      "id": "paragraph_1625381734625_869528169",
      "dateCreated": "2021-07-04 08:55:34.625",
      "dateStarted": "2021-09-16 14:16:41.045",
      "dateFinished": "2021-09-16 14:17:02.419",
      "status": "FINISHED"
    },
    {
      "text": "def procesarQuijote(){\n    \n    //RDD\n    \n    val input \u003d sc.textFile(\"./notebook/quijote.txt\")\n    \n    val palabras \u003d input.flatMap(linea \u003d\u003e linea.toLowerCase.split(\"\\\\W+\"))\n    \n    val sumatorioPalabras \u003d palabras.countByValue()\n    \n    // print resultado\n    \n    sumatorioPalabras.foreach(println)\n}\n\nprocesarQuijote()",
      "user": "anonymous",
      "dateUpdated": "2021-09-16 14:17:02.468",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/media/jose/Repositorio/zeppelin-0.9.0-bin-all/bin/notebook/quijote.txt\n  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)\n  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)\n  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)\n  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:204)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)\n  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:273)\n  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:269)\n  at scala.Option.getOrElse(Option.scala:121)\n  at org.apache.spark.rdd.RDD.partitions(RDD.scala:269)\n  at org.apache.spark.Partitioner$$anonfun$4.apply(Partitioner.scala:78)\n  at org.apache.spark.Partitioner$$anonfun$4.apply(Partitioner.scala:78)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n  at scala.collection.immutable.List.foreach(List.scala:392)\n  at scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n  at scala.collection.immutable.List.map(List.scala:296)\n  at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:78)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:326)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:326)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n  at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:325)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$countByKey$1.apply(PairRDDFunctions.scala:370)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n  at org.apache.spark.rdd.PairRDDFunctions.countByKey(PairRDDFunctions.scala:369)\n  at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1259)\n  at org.apache.spark.rdd.RDD$$anonfun$countByValue$1.apply(RDD.scala:1259)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n  at org.apache.spark.rdd.RDD.countByValue(RDD.scala:1258)\n  at procesarQuijote(\u003cconsole\u003e:42)\n  ... 51 elided\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625381804312_169067606",
      "id": "paragraph_1625381804312_169067606",
      "dateCreated": "2021-07-04 08:56:44.312",
      "dateStarted": "2021-09-16 14:17:02.485",
      "dateFinished": "2021-09-16 14:17:04.109",
      "status": "ERROR"
    },
    {
      "text": "//",
      "user": "anonymous",
      "dateUpdated": "2021-07-04 09:14:16.464",
      "progress": 50,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625381894319_1750618940",
      "id": "paragraph_1625381894319_1750618940",
      "dateCreated": "2021-07-04 08:58:14.319",
      "dateStarted": "2021-07-04 09:14:16.479",
      "dateFinished": "2021-07-04 09:14:16.587",
      "status": "FINISHED"
    },
    {
      "user": "anonymous",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1625382532990_2062403090",
      "id": "paragraph_1625382532990_2062403090",
      "dateCreated": "2021-07-04 09:08:52.990",
      "status": "READY"
    }
  ],
  "name": "Contar Palabras Quijote",
  "id": "2GCS2V4YD",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {
    "isRunning": true
  }
}