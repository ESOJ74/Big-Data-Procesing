{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    " .builder\n",
    " .appName(\"Nombre_App\") \n",
    " .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib hands-on: RandomForest para predecir la severidad del retraso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset está compuesto por las siguientes variables:\n",
    "\n",
    "1. **Year** 2008\n",
    "2. **Month** 1\n",
    "3. **DayofMonth** 1-31\n",
    "4. **DayOfWeek** 1 (Monday) - 7 (Sunday)\n",
    "5. **DepTime** hora real de salida (local, hhmm)\n",
    "6. **CRSDepTime** hora prevista de salida (local, hhmm)\n",
    "7. **ArrTime** hora real de llegada (local, hhmm)\n",
    "8. **CRSArrTime** hora prevista de llegada (local, hhmm)\n",
    "9. **UniqueCarrier** código del aparato\n",
    "10. **FlightNum** número de vuelo\n",
    "11. **TailNum** identificador de cola: aircraft registration, unique aircraft identifier\n",
    "12. **ActualElapsedTime** tiempo real invertido en el vuelo\n",
    "13. **CRSElapsedTime** en minutos\n",
    "14. **AirTime** en minutos\n",
    "15. **ArrDelay** retraso a la llegada, en minutos: se considera que un vuelo ha llegado \"on time\" si aterrizó menos de 15 minutos más tarde de la hora prevista en el Computerized Reservations Systems (CRS).\n",
    "16. **DepDelay** retraso a la salida, en minutos\n",
    "17. **Origin** código IATA del aeropuerto de origen\n",
    "18. **Dest** código IATA del aeropuerto de destino\n",
    "19. **Distance** en millas\n",
    "20. **TaxiIn** taxi in time, in minutes\n",
    "21. **TaxiOut** taxi out time in minutes\n",
    "22. **Cancelled** *si el vuelo fue cancelado (1 = sí, 0 = no)\n",
    "23. **CancellationCode** razón de cancelación (A = aparato, B = tiempo atmosférico, C = NAS, D = seguridad)\n",
    "24. **Diverted** *si el vuelo ha sido desviado (1 = sí, 0 = no)\n",
    "25. **CarrierDelay** en minutos: El retraso del transportista está bajo el control del transportista aéreo. Ejemplos de sucesos que pueden determinar el retraso del transportista son: limpieza de la aeronave, daño de la aeronave, espera de la llegada de los pasajeros o la tripulación de conexión, equipaje, impacto de un pájaro, carga de equipaje, servicio de comidas, computadora, equipo del transportista, problemas legales de la tripulación (descanso del piloto o acompañante) , daños por mercancías peligrosas, inspección de ingeniería, abastecimiento de combustible, pasajeros discapacitados, tripulación retrasada, servicio de inodoros, mantenimiento, ventas excesivas, servicio de agua potable, denegación de viaje a pasajeros en mal estado, proceso de embarque muy lento, equipaje de mano no válido, retrasos de peso y equilibrio.\n",
    "26. **WeatherDelay** en minutos: causado por condiciones atmosféricas extremas o peligrosas, previstas o que se han manifestado antes del despegue, durante el viaje, o a la llegada.\n",
    "27. **NASDelay** en minutos: retraso causado por el National Airspace System (NAS) por motivos como condiciones meteorológicas (perjudiciales pero no extremas), operaciones del aeropuerto, mucho tráfico aéreo, problemas con los controladores aéreos, etc.\n",
    "28. **SecurityDelay** en minutos: causado por la evacuación de una terminal, re-embarque de un avión debido a brechas en la seguridad, fallos en dispositivos del control de seguridad, colas demasiado largas en el control de seguridad, etc.\n",
    "29. **LateAircraftDelay** en minutos: debido al propio retraso del avión al llegar, problemas para conseguir aterrizar en un aeropuerto a una hora más tardía de la que estaba prevista."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE:** Vamos a emplear una versión reducida del dataset de vuelos para entender la forma de trabajar con MLlib, y en particular, los mecanimos de exploración de combinaciones de híper-parámetros para encontrar el mejor modelo, los cuales requieren ajustar varios modelos distintos varias veces. Este proceso sería demasiado largo si utilizásemos el dataset original de 300 MB. \n",
    "\n",
    "<p>En la siguiente celda, descargaremos este dataset reducido de Internet mediante la ejecución del comandos de Linux `wget` y lo subiremos a HDFS  con el comando de HDFS `copyFromLocal`. Los datos guardados en HDFS son volátiles y desaparecerán cuando el cluster sea desmantelado.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a utilizar una versión reducida del dataset original para poder ver en funcionamiento el ajuste de hiper-parámetros, que requiere ajustar varios modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descargamos el CSV reducido y lo subimos a HDFS (esta vez no es Google Cloud Storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-04 05:53:18--  https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flights_jan08.csv\n",
      "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[185.199.109.133]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 9719583 (9,3M) [text/plain]\n",
      "Guardando como: “flights_jan08.csv”\n",
      "\n",
      "flights_jan08.csv   100%[===================>]   9,27M  18,2MB/s    en 0,5s    \n",
      "\n",
      "2021-10-04 05:53:19 (18,2 MB/s) - “flights_jan08.csv” guardado [9719583/9719583]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/olbapjose/xapi-clojure/master/flights_jan08.csv\n",
    "#!hdfs dfs -copyFromLocal flights_jan08.csv /tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ahora lo leemos desde la ruta /tmp/flights_jan08.csv de HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el dataset de HDFS. Esta operación todavía no hace la lectura hace una pasada \n",
    "# sobre los datos para inferir el esquema\n",
    "flightsDF = spark.read.option(\"header\", \"true\")\\\n",
    "                      .option(\"inferSchema\", \"true\")\\\n",
    "                      .csv(\"Datasets/flights_jan08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightsDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar algunos transformadores habituales, y un algoritmo RandomForest que es un estimador. Utilizaremos:\n",
    "\n",
    "* StringIndexer para convertir variables tipo String en variables categóricas pero cuyos valores son números reales con la parte decimal a 0, tal como necesitan los algoritmos de Spark.\n",
    "* Bucketizer para discretizar la columna de ArrDelay sin dar nombre a las categorías, solo numeros. Será nuestra variable target.\n",
    "* VectorAssembler para unir las columnas de las features en una sola de tipo vector\n",
    "* RandomForest que es un estimador, como algoritmo de predicción de la severidad\n",
    "* Pipeline, que es un estimador y que incluirá todos los elementos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanFlightsDF = flightsDF.where(\"ArrDelay != 'NA' and DepDelay != 'NA' and DepTime != 'NA' and ArrTime != 'NA'\")\\\n",
    "                          .withColumn(\"ArrDelay\", F.col(\"ArrDelay\").cast(IntegerType()))\\\n",
    "                          .withColumn(\"DepDelay\", F.col(\"DepDelay\").cast(IntegerType()))\\\n",
    "                          .withColumn(\"ArrTime\", F.col(\"ArrTime\").cast(IntegerType()))\\\n",
    "                          .withColumn(\"DepTime\", F.col(\"DepTime\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos tres categorías: <15, entre 15 y 60, >60. \n",
    "# Cada una se codifica con un número real: 0.0, 1.0, 2.0 \n",
    "\n",
    "splitsDelays = [-float(\"inf\"), 15, 60, float(\"inf\")]\n",
    "arrDelayBucketizer = Bucketizer(splits=splitsDelays, \n",
    "                                inputCol=\"ArrDelay\", \n",
    "                                outputCol=\"ArrDelayBucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos varias franjas: 00:00 - 06:00, 06:00 - 12:00, 12:00 - 18:00, \n",
    "#                           18:00 - 22:00, 22:00 - 00:00\n",
    "\n",
    "splitsDepTime = [-1, 600, 1200, 1800, 2200, 2500]\n",
    "depTimeBucketizer = Bucketizer(splits=splitsDepTime, \n",
    "                               inputCol=\"DepTime\", \n",
    "                               outputCol=\"DepTimeBucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos en train y test de manera aleatoria usando la semilla 123 para los números aleatorios, para que sea reproducible. \n",
    "# Esto devuelve una lista de dos DataFrames. La división hará que el primer elemento de la lista sea un DF \n",
    "# con aprox. el 70 % de las filas. Lo usaremos para entrenar. El otro DF tendrá aprox el 30 % restante de las filas. \n",
    "\n",
    "splits = cleanFlightsDF.randomSplit([0.7, 0.3], \n",
    "                                    seed = 123)\n",
    "trainDF = splits[0].cache() # El primer DF tiene el 70 % de los datos\n",
    "testDF = splits[1].cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si quisiera generar la lista con todos los StringIndexer para TODAS las columnas:\n",
    "# categoricas = [\"asdñfkj\", \"añdslkjadf\"]\n",
    "# indexerList = [StringIndexer(inputCol=c, \n",
    "#                              outputCol=c + \"indexed\", \n",
    "#                              handleInvalid=\"skip\") for c in categoricas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexamos las columnas categóricas Origin, Dest y DayOfWeek, para traducirlas a reales con la parte decimal a 0.\n",
    "# Recordemos que esto también introduce metadatos adicionales en la columna resultante para indicar que, aunque sea\n",
    "# una columna de números reales, en realidad están representando categorías y debe ser tratada como tal por el algoritmo\n",
    "originIndexer = StringIndexer(inputCol = \"Origin\", \n",
    "                              outputCol=\"OriginIndexed\", \n",
    "                              handleInvalid=\"skip\")\n",
    "destIndexer = StringIndexer(inputCol = \"Dest\", \n",
    "                            outputCol=\"DestIndexed\", \n",
    "                            handleInvalid=\"skip\")\n",
    "dowIndexer = StringIndexer(inputCol = \"DayOfWeek\", \n",
    "                           outputCol=\"DayOfWeekIndexed\", \n",
    "                           handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora unimos todas las columnas que se usarán como variables en una sola columna de tipo vector llamada featuresVector\n",
    "vectorAssembler = VectorAssembler(inputCols = [\"DepDelay\", \n",
    "                                               \"DepTimeBucketed\", \n",
    "                                               \"OriginIndexed\", \n",
    "                                               \"DestIndexed\", \n",
    "                                               \"DayOfWeekIndexed\"], \n",
    "                                  outputCol = \"featuresVector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(featuresCol = \"featuresVector\",\n",
    "                                      labelCol = \"ArrDelayBucketed\",\n",
    "                                      numTrees = 50, \n",
    "                                      maxBins=100)\n",
    "\n",
    "pipeline = Pipeline(stages=[arrDelayBucketizer, \n",
    "                            depTimeBucketizer, \n",
    "                            dowIndexer, \n",
    "                            originIndexer, \n",
    "                            destIndexer, \n",
    "                            vectorAssembler, \n",
    "                            randomForest])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos fit para ajustar el pipeline completo. Lo que esto hace es, para cada etapa:\n",
    "- Si la etapa es un Transformer, invoca al método transform() pasándole el DF que recibe de la etapa anterior,\n",
    "  y envía el resultado (DF transformado) a la etapa siguiente del pipeline.\n",
    "- Si la etapa es un Estimator, invoca al método fit() pasándole como argumento el DF recibido de la etapa anterior,\n",
    "  y después invoca transform() sobre el objeto devuelto por fit, pasando de nuevo dicho DF como argumento. \n",
    "  Finalmente el DF devuelvo por transform es enviado a la etapa siguiente del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Bucketizer_ff3db6b6da04,\n",
       " Bucketizer_6ba0b07155b2,\n",
       " StringIndexerModel: uid=StringIndexer_af985d2375f2, handleInvalid=skip,\n",
       " StringIndexerModel: uid=StringIndexer_ba8d3b35fa93, handleInvalid=skip,\n",
       " StringIndexerModel: uid=StringIndexer_e7fcce327d46, handleInvalid=skip,\n",
       " VectorAssembler_29e2603e6c5d,\n",
       " RandomForestClassificationModel: uid=RandomForestClassifier_a2d064398510, numTrees=50, numClasses=3, numFeatures=5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-inf, 15.0, 60.0, inf]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelineModel.stages[0].getSplits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer predicciones sobre los datos de test. Esto devolverá un nuevo DF al que se le han añadido varias columnas al final:\n",
    "1. **`rawPrediction`**: magnitud que tiene una interpretación diferente según el algoritmo pero que intuitivamente nos da una\n",
    "  medida de la confianza en cada posible clase (cuanto mayor, más confianza se tiene en que esa es la clase del ejemplo). En\n",
    "  nuestro caso será un vector de 3 números reales puesto que nuestro problema tiene 3 clases\n",
    "2. **`probability`**: vector de probabilidades de que el ejemplo pertenezca a cada una de las 3 clases de nuestro problema\n",
    "3. **`prediction`**: clase para la cual la rawProbability es mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 69152 ejemplos de entrenamiento\n"
     ]
    }
   ],
   "source": [
    "print(\"Hay {0} ejemplos de entrenamiento\".format(trainDF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "      <th>ArrDelayBucketed</th>\n",
       "      <th>DepTimeBucketed</th>\n",
       "      <th>DayOfWeekIndexed</th>\n",
       "      <th>OriginIndexed</th>\n",
       "      <th>DestIndexed</th>\n",
       "      <th>featuresVector</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>711</td>\n",
       "      <td>715</td>\n",
       "      <td>WN</td>\n",
       "      <td>2111</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[0.0, 1.0, 4.0, 7.0, 0.0]</td>\n",
       "      <td>[47.6674061185668, 2.2904215096657694, 0.04217...</td>\n",
       "      <td>[0.9533481223713361, 0.045808430193315396, 0.0...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>601</td>\n",
       "      <td>600</td>\n",
       "      <td>719</td>\n",
       "      <td>720</td>\n",
       "      <td>WN</td>\n",
       "      <td>1940</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>[1.0, 1.0, 27.0, 26.0, 0.0]</td>\n",
       "      <td>[47.77524112449889, 2.1812078517622133, 0.0435...</td>\n",
       "      <td>[0.955504822489978, 0.043624157035244276, 0.00...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>602</td>\n",
       "      <td>600</td>\n",
       "      <td>733</td>\n",
       "      <td>730</td>\n",
       "      <td>WN</td>\n",
       "      <td>3233</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[2.0, 1.0, 0.0, 4.0, 0.0]</td>\n",
       "      <td>[47.4190118106295, 2.5387376472074616, 0.04225...</td>\n",
       "      <td>[0.9483802362125902, 0.05077475294414924, 0.00...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "      <td>723</td>\n",
       "      <td>730</td>\n",
       "      <td>WN</td>\n",
       "      <td>3330</td>\n",
       "      <td>...</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[0.0, 1.0, 4.0, 30.0, 0.0]</td>\n",
       "      <td>[47.739289505198556, 2.210250050316093, 0.0504...</td>\n",
       "      <td>[0.9547857901039712, 0.04420500100632187, 0.00...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>607</td>\n",
       "      <td>600</td>\n",
       "      <td>831</td>\n",
       "      <td>810</td>\n",
       "      <td>WN</td>\n",
       "      <td>922</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[7.0, 1.0, 11.0, 3.0, 0.0]</td>\n",
       "      <td>[47.50520246680057, 2.39803243352218, 0.096765...</td>\n",
       "      <td>[0.9501040493360116, 0.04796064867044361, 0.00...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29533</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2342</td>\n",
       "      <td>2005</td>\n",
       "      <td>47</td>\n",
       "      <td>2120</td>\n",
       "      <td>WN</td>\n",
       "      <td>470</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>[217.0, 4.0, 23.0, 16.0, 0.0]</td>\n",
       "      <td>[0.052585987261146494, 2.305320672305464, 47.6...</td>\n",
       "      <td>[0.0010517197452229302, 0.04610641344610929, 0...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29534</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2344</td>\n",
       "      <td>1940</td>\n",
       "      <td>320</td>\n",
       "      <td>2205</td>\n",
       "      <td>WN</td>\n",
       "      <td>1777</td>\n",
       "      <td>...</td>\n",
       "      <td>223</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[244.0, 4.0, 1.0, 8.0, 0.0]</td>\n",
       "      <td>[0.6813745318006782, 2.4861041575955904, 46.83...</td>\n",
       "      <td>[0.013627490636013569, 0.04972208315191183, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29535</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2344</td>\n",
       "      <td>2105</td>\n",
       "      <td>116</td>\n",
       "      <td>2235</td>\n",
       "      <td>WN</td>\n",
       "      <td>1274</td>\n",
       "      <td>...</td>\n",
       "      <td>156</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[159.0, 4.0, 0.0, 40.0, 0.0]</td>\n",
       "      <td>[0.5843394913694113, 2.0243409239836883, 47.39...</td>\n",
       "      <td>[0.011686789827388232, 0.04048681847967378, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29536</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2352</td>\n",
       "      <td>2045</td>\n",
       "      <td>256</td>\n",
       "      <td>2330</td>\n",
       "      <td>WN</td>\n",
       "      <td>1442</td>\n",
       "      <td>...</td>\n",
       "      <td>167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[187.0, 4.0, 1.0, 2.0, 0.0]</td>\n",
       "      <td>[0.6813745318006782, 2.3278953895994037, 46.99...</td>\n",
       "      <td>[0.013627490636013567, 0.04655790779198809, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29537</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>2357</td>\n",
       "      <td>2015</td>\n",
       "      <td>212</td>\n",
       "      <td>2230</td>\n",
       "      <td>WN</td>\n",
       "      <td>1250</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>[222.0, 4.0, 39.0, 11.0, 0.0]</td>\n",
       "      <td>[0.052585987261146494, 2.5936872483873943, 47....</td>\n",
       "      <td>[0.0010517197452229302, 0.0518737449677479, 0....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29538 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0      2008      1           3          4      600         600      711   \n",
       "1      2008      1           3          4      601         600      719   \n",
       "2      2008      1           3          4      602         600      733   \n",
       "3      2008      1           3          4      605         605      723   \n",
       "4      2008      1           3          4      607         600      831   \n",
       "...     ...    ...         ...        ...      ...         ...      ...   \n",
       "29533  2008      1          31          4     2342        2005       47   \n",
       "29534  2008      1          31          4     2344        1940      320   \n",
       "29535  2008      1          31          4     2344        2105      116   \n",
       "29536  2008      1          31          4     2352        2045      256   \n",
       "29537  2008      1          31          4     2357        2015      212   \n",
       "\n",
       "       CRSArrTime UniqueCarrier  FlightNum  ... LateAircraftDelay  \\\n",
       "0             715            WN       2111  ...                NA   \n",
       "1             720            WN       1940  ...                NA   \n",
       "2             730            WN       3233  ...                NA   \n",
       "3             730            WN       3330  ...                NA   \n",
       "4             810            WN        922  ...                 0   \n",
       "...           ...           ...        ...  ...               ...   \n",
       "29533        2120            WN        470  ...               207   \n",
       "29534        2205            WN       1777  ...               223   \n",
       "29535        2235            WN       1274  ...               156   \n",
       "29536        2330            WN       1442  ...               167   \n",
       "29537        2230            WN       1250  ...               222   \n",
       "\n",
       "      ArrDelayBucketed  DepTimeBucketed DayOfWeekIndexed  OriginIndexed  \\\n",
       "0                  0.0              1.0              0.0            4.0   \n",
       "1                  0.0              1.0              0.0           27.0   \n",
       "2                  0.0              1.0              0.0            0.0   \n",
       "3                  0.0              1.0              0.0            4.0   \n",
       "4                  1.0              1.0              0.0           11.0   \n",
       "...                ...              ...              ...            ...   \n",
       "29533              2.0              4.0              0.0           23.0   \n",
       "29534              2.0              4.0              0.0            1.0   \n",
       "29535              2.0              4.0              0.0            0.0   \n",
       "29536              2.0              4.0              0.0            1.0   \n",
       "29537              2.0              4.0              0.0           39.0   \n",
       "\n",
       "       DestIndexed                 featuresVector  \\\n",
       "0              7.0      [0.0, 1.0, 4.0, 7.0, 0.0]   \n",
       "1             26.0    [1.0, 1.0, 27.0, 26.0, 0.0]   \n",
       "2              4.0      [2.0, 1.0, 0.0, 4.0, 0.0]   \n",
       "3             30.0     [0.0, 1.0, 4.0, 30.0, 0.0]   \n",
       "4              3.0     [7.0, 1.0, 11.0, 3.0, 0.0]   \n",
       "...            ...                            ...   \n",
       "29533         16.0  [217.0, 4.0, 23.0, 16.0, 0.0]   \n",
       "29534          8.0    [244.0, 4.0, 1.0, 8.0, 0.0]   \n",
       "29535         40.0   [159.0, 4.0, 0.0, 40.0, 0.0]   \n",
       "29536          2.0    [187.0, 4.0, 1.0, 2.0, 0.0]   \n",
       "29537         11.0  [222.0, 4.0, 39.0, 11.0, 0.0]   \n",
       "\n",
       "                                           rawPrediction  \\\n",
       "0      [47.6674061185668, 2.2904215096657694, 0.04217...   \n",
       "1      [47.77524112449889, 2.1812078517622133, 0.0435...   \n",
       "2      [47.4190118106295, 2.5387376472074616, 0.04225...   \n",
       "3      [47.739289505198556, 2.210250050316093, 0.0504...   \n",
       "4      [47.50520246680057, 2.39803243352218, 0.096765...   \n",
       "...                                                  ...   \n",
       "29533  [0.052585987261146494, 2.305320672305464, 47.6...   \n",
       "29534  [0.6813745318006782, 2.4861041575955904, 46.83...   \n",
       "29535  [0.5843394913694113, 2.0243409239836883, 47.39...   \n",
       "29536  [0.6813745318006782, 2.3278953895994037, 46.99...   \n",
       "29537  [0.052585987261146494, 2.5936872483873943, 47....   \n",
       "\n",
       "                                             probability prediction  \n",
       "0      [0.9533481223713361, 0.045808430193315396, 0.0...        0.0  \n",
       "1      [0.955504822489978, 0.043624157035244276, 0.00...        0.0  \n",
       "2      [0.9483802362125902, 0.05077475294414924, 0.00...        0.0  \n",
       "3      [0.9547857901039712, 0.04420500100632187, 0.00...        0.0  \n",
       "4      [0.9501040493360116, 0.04796064867044361, 0.00...        0.0  \n",
       "...                                                  ...        ...  \n",
       "29533  [0.0010517197452229302, 0.04610641344610929, 0...        2.0  \n",
       "29534  [0.013627490636013569, 0.04972208315191183, 0....        2.0  \n",
       "29535  [0.011686789827388232, 0.04048681847967378, 0....        2.0  \n",
       "29536  [0.013627490636013567, 0.04655790779198809, 0....        2.0  \n",
       "29537  [0.0010517197452229302, 0.0518737449677479, 0....        2.0  \n",
       "\n",
       "[29538 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsDF.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo (evaluamos las predicciones que hemos hecho sobre el DF de test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0788476 \n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Objeto evaluador, para evaluar las predicciones. Compara una columna de predicciones con la columna target del verdadero valor\n",
    "# Hay varias métricas posibles, pero nosotros hemos elegido la más simple: porcentaje de acierto en clasificación.\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ArrDelayBucketed\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictionsDF)\n",
    "\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de híper-parámetros utilizando Cross Validation sobre el subconjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_34024880dbb1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "# Objeto ParamGrid al que le tenemos que indicar cada uno de los parámetros sobre los que queremos buscar,\n",
    "# y la lista de valores posibles que queremos probar con cada uno. Deben ser parámetros tomados directamente\n",
    "# del objeto estimador que se añadió al pipeline (no pueden ser de ningún otro modelo). En nuestro caso este objeto\n",
    "# está almacenado en la variable randomForest que habíamos creado en celdas anteriores.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(randomForest.numTrees, [50, 100, 150])\\\n",
    "    .addGrid(randomForest.maxDepth, [3, 4, 5])\\\n",
    "    .build() # como tenemos 2 parámetros con 3 valores posibles cada uno, hay 9 combinaciones posibles\n",
    "\n",
    "# CrossValidator es un estimador. Cuando invocamos a fit(), probará todas las combinaciones de valores de los \n",
    "# parámetros, invocando con cada combinación al método fit() del objeto pipeline que le hemos pasado como argumento\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Como hemos hecho 3 folds, habrá que entrenar 3 veces cada modelo candidato (cada combinación de parámetros)\n",
    "# y obtener su media de accuracy. En total vamos a entrenar 27 modelos\n",
    "\n",
    "cvModel = crossval.fit(trainDF)\n",
    "cvModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='CrossValidatorModel_ba528baa59ff', name='seed', doc='random seed.'): -7553321941270344866,\n",
       " Param(parent='CrossValidatorModel_ba528baa59ff', name='numFolds', doc='number of folds for cross validation'): 3,\n",
       " Param(parent='CrossValidatorModel_ba528baa59ff', name='foldCol', doc=\"Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won't do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers.\"): '',\n",
       " Param(parent='CrossValidatorModel_ba528baa59ff', name='estimator', doc='estimator to be cross-validated'): Pipeline_66810f493438,\n",
       " Param(parent='CrossValidatorModel_ba528baa59ff', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 50,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 50,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 50,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 100,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 100,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 100,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 150,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 150,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 4},\n",
       "  {Param(parent='RandomForestClassifier_a2d064398510', name='numTrees', doc='Number of trees to train (>= 1).'): 150,\n",
       "   Param(parent='RandomForestClassifier_a2d064398510', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}],\n",
       " Param(parent='CrossValidatorModel_ba528baa59ff', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): MulticlassClassificationEvaluator_3e1146936333}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El objeto RandomForestModel (modelo ajustado presente en la última etapa del pipeline ya ajustado) dispone de ciertos atajos para recuperar valores de algunos parámetros (por ejemplo getNumTrees) pero no de otros (por ejemplo, no existe getMaxDepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número óptimo de árboles: 50\n",
      "Max depth óptimo: 5\n"
     ]
    }
   ],
   "source": [
    "rf = cvModel.bestModel.stages[6]\n",
    "print(\"Número óptimo de árboles: {0}\".format(rf.getNumTrees))\n",
    "print(\"Max depth óptimo: {0}\".format(rf.getOrDefault('maxDepth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
