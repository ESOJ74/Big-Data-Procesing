{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb90429",
   "metadata": {},
   "source": [
    "#### a. Descargar el Quijote\n",
    "https://gist.github.com/jsdario/6d6c69398cb0c73111e49f1218960f79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ef87a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [_c0: string]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// !wget \"https://gist.githubusercontent.com/jsdario/6d6c69398cb0c73111e49f1218960f79/raw/8d4fc4548d437e2a7203a5aeeace5477f598827d/el_quijote.txt\"\n",
    "val df = spark.read.option(\"header\", \"false\").csv(\"el_quijote.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5135368",
   "metadata": {},
   "source": [
    "Aplicar no solo count (para obtener el n√∫mero de l√≠neas) y show sino probar distintas\n",
    "sobrecargas del m√©todo show (con/sin truncate, indicando/sin indicar num de filas,\n",
    "etc) as√≠ como tambi√©n los m√©todos, head, take, first (diferencias entre estos 3?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0c4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: Long = 2185\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42a833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|_c0                         |\n",
      "+----------------------------+\n",
      "|DON QUIJOTE DE LA MANCHA    |\n",
      "|Miguel de Cervantes Saavedra|\n",
      "|PRIMERA PARTE               |\n",
      "+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3,truncate = false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2685ca39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[org.apache.spark.sql.Row] = Array([DON QUIJOTE DE LA MANCHA], [Miguel de Cervantes Saavedra], [PRIMERA PARTE])\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70d18b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[org.apache.spark.sql.Row] = Array([DON QUIJOTE DE LA MANCHA], [Miguel de Cervantes Saavedra], [PRIMERA PARTE])\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2685a0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: org.apache.spark.sql.Row = [DON QUIJOTE DE LA MANCHA]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58c1d0",
   "metadata": {},
   "source": [
    "#### b. Del ejercicio de M&M aplicar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549b5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   TX|   Red|   10|\n",
      "|   NV|  Blue|   66|\n",
      "|   CO|  Blue|   79|\n",
      "|   OR|  Blue|   71|\n",
      "|   WA|Yellow|   93|\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mnm_file: String = mnm_dataset.csv\n",
       "mnm_df: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mnm_file = \"mnm_dataset.csv\"\n",
    "val mnm_df = spark\n",
    "            .read\n",
    "            .option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .csv(mnm_file)\n",
    "mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950ce6e",
   "metadata": {},
   "source": [
    "i. Otras operaciones de agregaci√≥n como el Max con otro tipo de ordenamiento (descendiente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63113b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|State| Color|Maximo|\n",
      "+-----+------+------+\n",
      "|   CO|  Blue|   100|\n",
      "|   NM|Orange|   100|\n",
      "|   UT|  Blue|   100|\n",
      "|   WA|Orange|   100|\n",
      "|   WY| Green|   100|\n",
      "+-----+------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "max_mnm_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//import spark.sql.functions \n",
    "val max_mnm_df = (mnm_df\n",
    "                    .select(\"State\", \"Color\", \"Count\")\n",
    "                    .groupBy(\"State\", \"Color\")\n",
    "                    .agg(max(\"Count\").alias(\"Maximo\"))\n",
    "                    .orderBy(desc(\"Maximo\")))\n",
    "max_mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a3c611",
   "metadata": {},
   "source": [
    "ii. hacer un ejercicio como el ‚Äúwhere‚Äù de CA que aparece en el libro pero\n",
    "indicando m√°s opciones de estados (p.e. NV, TX, CA, CO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7634aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CO|Yellow| 1721|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "|   NV| Green| 1698|\n",
      "|   CO|  Blue| 1695|\n",
      "|   NV|Yellow| 1675|\n",
      "|   NV|  Blue| 1673|\n",
      "|   NV| Brown| 1657|\n",
      "|   CO| Brown| 1656|\n",
      "|   CO|Orange| 1642|\n",
      "|   CO|   Red| 1624|\n",
      "|   NV|   Red| 1610|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nv_co_count_mnm_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val nv_co_count_mnm_df = (mnm_df\n",
    "                             .select(\"State\", \"Color\", \"Count\")\n",
    "                             .where((col(\"State\") === \"NV\") or (col(\"State\") === \"CO\"))\n",
    "                             .groupBy(\"State\", \"Color\")\n",
    "                             .agg(count(\"Count\").alias(\"Total\"))\n",
    "                             .orderBy(desc(\"Total\")))\n",
    "nv_co_count_mnm_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee4a869",
   "metadata": {},
   "source": [
    "iii. Hacer un ejercicio donde se calculen en una misma operaci√≥n el Max, Min, Avg, Count. Revisar el API (documentaci√≥n) donde encontrar√°n este ejemplo: ds.agg(max(\"ùëéùëîùëí\"),ùëéùë£ùëî(\"salary\")) ds.groupBy().agg(max(\"ùëéùëîùëí\"),ùëéùë£ùëî(\"salary\")) NOTA: $ es un alias de col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f920751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+---+---+------+\n",
      "|State| Color|Total|Max|Min|   Avg|\n",
      "+-----+------+-----+---+---+------+\n",
      "|   WY| Green| 1695|100| 10|55.657|\n",
      "|   NV|   Red| 1610|100| 10|55.494|\n",
      "|   UT|  Blue| 1655|100| 10|54.367|\n",
      "|   WA|Orange| 1658|100| 10|  55.2|\n",
      "|   NM| Green| 1682|100| 10|54.197|\n",
      "+-----+------+-----+---+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "op_mnm_df: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val op_mnm_df = (mnm_df\n",
    "                   .select(\"State\", \"Color\", \"Count\")\n",
    "                   .groupBy(\"State\", \"Color\")\n",
    "                   .agg(\n",
    "                         count(\"Count\").alias(\"Total\"),\n",
    "                         max(\"Count\").alias(\"Max\"),\n",
    "                         min(\"Count\").alias(\"Min\"),\n",
    "                         round(avg(\"Count\"),3).alias(\"Avg\")\n",
    "                       )\n",
    "                )\n",
    "op_mnm_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06898cfb",
   "metadata": {},
   "source": [
    "iv. Hacer tambi√©n ejercicios en SQL creando tmpView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9680ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   TX|   Red|   10|\n",
      "|   NV|  Blue|   66|\n",
      "|   CO|  Blue|   79|\n",
      "|   OR|  Blue|   71|\n",
      "|   WA|Yellow|   93|\n",
      "+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnm_df.createOrReplaceTempView(\"mnm\")\n",
    "spark.sql(\"\"\"SELECT * FROM mnm\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54a8c1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+------+------+------+\n",
      "|State| Color|Total|Maximo|Minimo|   Avg|\n",
      "+-----+------+-----+------+------+------+\n",
      "|   WY| Green| 1695|   100|    10|55.657|\n",
      "|   NV|   Red| 1610|   100|    10|55.494|\n",
      "|   UT|  Blue| 1655|   100|    10|54.367|\n",
      "|   WA|Orange| 1658|   100|    10|  55.2|\n",
      "|   NM| Green| 1682|   100|    10|54.197|\n",
      "|   CA|  Blue| 1603|   100|    10|55.598|\n",
      "|   WA|   Red| 1671|   100|    10|55.854|\n",
      "|   NV| Brown| 1657|   100|    10|55.811|\n",
      "|   AZ| Green| 1676|   100|    10|54.822|\n",
      "|   CA|   Red| 1656|   100|    10| 55.27|\n",
      "|   AZ|Orange| 1689|   100|    10|54.283|\n",
      "|   CO|  Blue| 1695|   100|    10| 55.11|\n",
      "|   NM|Orange| 1665|   100|    10|54.805|\n",
      "|   NM|Yellow| 1688|   100|    10|54.945|\n",
      "|   WY|Orange| 1595|   100|    10|55.145|\n",
      "|   UT|Yellow| 1645|   100|    10|54.264|\n",
      "|   WY|   Red| 1670|   100|    10|54.951|\n",
      "|   OR|  Blue| 1646|   100|    10|54.998|\n",
      "|   NV|Orange| 1712|   100|    10|54.865|\n",
      "|   AZ|Yellow| 1654|   100|    10|54.985|\n",
      "+-----+------+-----+------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT State,\n",
    "                    Color,\n",
    "                    count(Count) as Total,\n",
    "                    max(Count) as Maximo,\n",
    "                    min(Count) as Minimo,\n",
    "                    round(avg(Count),3) as Avg\n",
    "             FROM mnm\n",
    "             GROUP BY State,Color\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3556c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT State,Color,COUNT(*) as Cantidad\n",
    "             FROM mnm  \n",
    "             WHERE State = \"TX\" \n",
    "             GROUP BY State,Color\n",
    "             ORDER BY Cantidad DESC\n",
    "             \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92444020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
