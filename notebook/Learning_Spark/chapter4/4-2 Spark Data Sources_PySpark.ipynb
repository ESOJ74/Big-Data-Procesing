{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002acbac",
   "metadata": {},
   "source": [
    "Spark Data Sources\n",
    "This notebook shows how to use Spark Data Sources Interface API to read file formats:\n",
    "\n",
    "* Parquet\n",
    "* JSON\n",
    "* CSV\n",
    "* Avro\n",
    "* ORC\n",
    "* Image\n",
    "* Binary\n",
    "\n",
    "A full list of DataSource methods is available here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa75f0e",
   "metadata": {},
   "source": [
    "Define paths for the various data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8beb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = \"../databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet\"\n",
    "json_file = \"../databricks-datasets/learning-spark-v2/flights/summary-data/json/*\"\n",
    "csv_file = \"../databricks-datasets/learning-spark-v2/flights/summary-data/csv/*\"\n",
    "orc_file = \"../databricks-datasets/learning-spark-v2/flights/summary-data/orc/*\"\n",
    "avro_file = \"../databricks-datasets/learning-spark-v2/flights/summary-data/avro/*\"\n",
    "schema = \"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9314704",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#create a SparkSession\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Example-3_6\")\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-avro_2.12:3.1.2\")\n",
    "    .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726b05a",
   "metadata": {},
   "source": [
    "## Parquet Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4956051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "      .format(\"parquet\")\n",
    "      .option(\"path\", parquet_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df60ba3",
   "metadata": {},
   "source": [
    "Another way to read this same data using a variation of this API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346a7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (spark.\n",
    "       read.\n",
    "       parquet(parquet_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b34ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEST_COUNTRY_NAME</th>\n",
       "      <th>ORIGIN_COUNTRY_NAME</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>India</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>United States</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United States</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United States</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>United States</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senegal</td>\n",
       "      <td>United States</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United States</td>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEST_COUNTRY_NAME ORIGIN_COUNTRY_NAME  count\n",
       "0      United States             Romania      1\n",
       "1      United States             Ireland    264\n",
       "2      United States               India     69\n",
       "3              Egypt       United States     24\n",
       "4  Equatorial Guinea       United States      1\n",
       "5      United States           Singapore     25\n",
       "6      United States             Grenada     54\n",
       "7         Costa Rica       United States    477\n",
       "8            Senegal       United States     29\n",
       "9      United States    Marshall Islands     44"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(10, False)\n",
    "df2.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0f3a10",
   "metadata": {},
   "source": [
    "## Use SQL\n",
    "This will create an unmanaged temporary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0df8cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY VIEW us_delay_flights_tbl\n",
    "        USING parquet\n",
    "            OPTIONS (\n",
    "              path \"../databricks-datasets/learning-spark-v2/flights/summary-data/parquet/2010-summary.parquet\"\n",
    "            )\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9fe72",
   "metadata": {},
   "source": [
    "Use SQL to query the table\n",
    "\n",
    "The outcome should be the same as one read into the DataFrame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf5db70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "954c9c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEST_COUNTRY_NAME</th>\n",
       "      <th>ORIGIN_COUNTRY_NAME</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>Romania</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>India</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>United States</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Equatorial Guinea</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United States</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United States</td>\n",
       "      <td>Grenada</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Costa Rica</td>\n",
       "      <td>United States</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senegal</td>\n",
       "      <td>United States</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United States</td>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEST_COUNTRY_NAME ORIGIN_COUNTRY_NAME  count\n",
       "0      United States             Romania      1\n",
       "1      United States             Ireland    264\n",
       "2      United States               India     69\n",
       "3              Egypt       United States     24\n",
       "4  Equatorial Guinea       United States      1\n",
       "5      United States           Singapore     25\n",
       "6      United States             Grenada     54\n",
       "7         Costa Rica       United States    477\n",
       "8            Senegal       United States     29\n",
       "9      United States    Marshall Islands     44"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(10, truncate=False)\n",
    "df.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3abf9",
   "metadata": {},
   "source": [
    "## JSON Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cb8056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"json\").option(\"path\", json_file).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe8b34ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "|United States    |Singapore          |1    |\n",
      "|United States    |Grenada            |62   |\n",
      "|Costa Rica       |United States      |588  |\n",
      "|Senegal          |United States      |40   |\n",
      "|Moldova          |United States      |1    |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48bc6d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e372331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |15   |\n",
      "|United States    |Croatia            |1    |\n",
      "|United States    |Ireland            |344  |\n",
      "|Egypt            |United States      |15   |\n",
      "|United States    |India              |62   |\n",
      "|United States    |Singapore          |1    |\n",
      "|United States    |Grenada            |62   |\n",
      "|Costa Rica       |United States      |588  |\n",
      "|Senegal          |United States      |40   |\n",
      "|Moldova          |United States      |1    |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3828930b",
   "metadata": {},
   "source": [
    "## CSV Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb4f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark\n",
    "      .read\n",
    "\t .format(\"csv\")\n",
    "\t .option(\"header\", \"true\")\n",
    "\t .schema(schema)\n",
    "\t .option(\"mode\", \"FAILFAST\")  # exit if any errors\n",
    "\t .option(\"nullValue\", \"\")\t  # replace any null data field with “”\n",
    "\t .option(\"path\", csv_file)\n",
    "\t .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9908135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a78af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.write.format(\"parquet\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"path\", \"/tmp/data/parquet/df_parquet\")\n",
    "  .option(\"compression\", \"snappy\")\n",
    "  .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf53985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: fs: orden no encontrada\r\n"
     ]
    }
   ],
   "source": [
    "!fs ls /tmp/data/parquet/df_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8bb71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (spark\n",
    "       .read\n",
    "       .option(\"header\", \"true\")\n",
    "       .option(\"mode\", \"FAILFAST\")\t # exit if any errors\n",
    "       .option(\"nullValue\", \"\")\n",
    "       .schema(schema)\n",
    "       .csv(csv_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f166f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b97aae7",
   "metadata": {},
   "source": [
    "## ORC Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cf94300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"orc\")\n",
    "      .option(\"path\", orc_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d8184e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3690ef",
   "metadata": {},
   "source": [
    "## Avro Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ea4ee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "      .format(\"avro\")\n",
    "      .option(\"path\", avro_file)\n",
    "      .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e791b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|United States    |Romania            |1    |\n",
      "|United States    |Ireland            |264  |\n",
      "|United States    |India              |69   |\n",
      "|Egypt            |United States      |24   |\n",
      "|Equatorial Guinea|United States      |1    |\n",
      "|United States    |Singapore          |25   |\n",
      "|United States    |Grenada            |54   |\n",
      "|Costa Rica       |United States      |477  |\n",
      "|Senegal          |United States      |29   |\n",
      "|United States    |Marshall Islands   |44   |\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31463a",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4535fcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n",
      "+------+-----+---------+----+-----+\n",
      "|height|width|nChannels|mode|label|\n",
      "+------+-----+---------+----+-----+\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |1    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "|288   |384  |3        |16  |0    |\n",
      "+------+-----+---------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import image\n",
    "\n",
    "image_dir = \"../databricks-datasets/learning-spark-v2/cctvVideos/train_images/\"\n",
    "images_df = spark.read.format(\"image\").load(image_dir)\n",
    "images_df.printSchema()\n",
    "\n",
    "images_df.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\", \"label\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac969e",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5691bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "|                path|   modificationTime|length|             content|label|\n",
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 55037|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54634|[FF D8 FF E0 00 1...|    1|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54624|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54505|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54475|[FF D8 FF E0 00 1...|    0|\n",
      "+--------------------+-------------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"../databricks-datasets/learning-spark-v2/cctvVideos/train_images/\"\n",
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "  .load(path))\n",
    "\n",
    "binary_files_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9e331e",
   "metadata": {},
   "source": [
    "To ignore any partitioning data discovery in a directory, you can set the recursiveFileLookup to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e9321bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 55037|[FF D8 FF E0 00 1...|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54634|[FF D8 FF E0 00 1...|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54624|[FF D8 FF E0 00 1...|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54505|[FF D8 FF E0 00 1...|\n",
      "|file:/media/jose/...|2021-04-15 02:34:17| 54475|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_files_df = (spark.read.format(\"binaryFile\")\n",
    "   .option(\"pathGlobFilter\", \"*.jpg\")\n",
    "   .option(\"recursiveFileLookup\", \"true\")\n",
    "   .load(path))\n",
    "binary_files_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18271114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
